<!DOCTYPE html>
<html style="display: none;" lang="zh">
    <head>
    <meta charset="utf-8">
    <!--
        © Material Theme
        https://github.com/viosey/hexo-theme-material
        Version: 1.5.0 -->
    <script>
        window.materialVersion = "1.5.0"
        // Delete localstorage with these tags
        window.oldVersion = [
            'codestartv1',
            '1.3.4',
            '1.4.0',
            '1.4.0b1'
        ]
    </script>

    <!-- dns prefetch -->
    <meta http-equiv="x-dns-prefetch-control" content="on">














    <!-- Title -->
    
    <title>
        
            CNN | 
        
        Azurery
    </title>

    <!-- Meta & Info -->
    <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <meta name="format-detection" content="telephone=no"/>
    <meta name="theme-color" content="#0097A7">
    <meta name="author" content="Magicmanoooo">
    <meta name="description" itemprop="description" content="蒟蒻一枚">
    <meta name="keywords" content=",DL">

    <!-- Import lsloader -->
    <script>(function(){window.lsloader={jsRunSequence:[],jsnamemap:{},cssnamemap:{}};lsloader.removeLS=function(key){try{localStorage.removeItem(key)}catch(e){}};lsloader.setLS=function(key,val){try{localStorage.setItem(key,val)}catch(e){}};lsloader.getLS=function(key){var val="";try{val=localStorage.getItem(key)}catch(e){val=""}return val};versionString="/*"+(window.materialVersion||"unknownVersion")+"*/";lsloader.clean=function(){try{var keys=[];for(var i=0;i<localStorage.length;i++){keys.push(localStorage.key(i))}keys.forEach(function(key){var data=lsloader.getLS(key);if(window.oldVersion){var remove=window.oldVersion.reduce(function(p,c){return p||data.indexOf("/*"+c+"*/")!==-1},false);if(remove){lsloader.removeLS(key)}}})}catch(e){}};lsloader.clean();lsloader.load=function(jsname,jspath,cssonload,isJs){if(typeof cssonload==="boolean"){isJs=cssonload;cssonload=undefined}isJs=isJs||false;cssonload=cssonload||function(){};var code;code=this.getLS(jsname);if(code&&code.indexOf(versionString)===-1){this.removeLS(jsname);this.requestResource(jsname,jspath,cssonload,isJs);return}if(code){var versionNumber=code.split(versionString)[0];if(versionNumber!=jspath){console.log("reload:"+jspath);this.removeLS(jsname);this.requestResource(jsname,jspath,cssonload,isJs);return}code=code.split(versionString)[1];if(isJs){this.jsRunSequence.push({name:jsname,code:code});this.runjs(jspath,jsname,code)}else{document.getElementById(jsname).appendChild(document.createTextNode(code));cssonload()}}else{this.requestResource(jsname,jspath,cssonload,isJs)}};lsloader.requestResource=function(name,path,cssonload,isJs){var that=this;if(isJs){this.iojs(path,name,function(path,name,code){that.setLS(name,path+versionString+code);that.runjs(path,name,code)})}else{this.iocss(path,name,function(code){document.getElementById(name).appendChild(document.createTextNode(code));that.setLS(name,path+versionString+code)},cssonload)}};lsloader.iojs=function(path,jsname,callback){var that=this;that.jsRunSequence.push({name:jsname,code:""});try{var xhr=new XMLHttpRequest;xhr.open("get",path,true);xhr.onreadystatechange=function(){if(xhr.readyState==4){if(xhr.status>=200&&xhr.status<300||xhr.status==304){if(xhr.response!=""){callback(path,jsname,xhr.response);return}}that.jsfallback(path,jsname)}};xhr.send(null)}catch(e){that.jsfallback(path,jsname)}};lsloader.iocss=function(path,jsname,callback,cssonload){var that=this;try{var xhr=new XMLHttpRequest;xhr.open("get",path,true);xhr.onreadystatechange=function(){if(xhr.readyState==4){if(xhr.status>=200&&xhr.status<300||xhr.status==304){if(xhr.response!=""){callback(xhr.response);cssonload();return}}that.cssfallback(path,jsname,cssonload)}};xhr.send(null)}catch(e){that.cssfallback(path,jsname,cssonload)}};lsloader.iofonts=function(path,jsname,callback,cssonload){var that=this;try{var xhr=new XMLHttpRequest;xhr.open("get",path,true);xhr.onreadystatechange=function(){if(xhr.readyState==4){if(xhr.status>=200&&xhr.status<300||xhr.status==304){if(xhr.response!=""){callback(xhr.response);cssonload();return}}that.cssfallback(path,jsname,cssonload)}};xhr.send(null)}catch(e){that.cssfallback(path,jsname,cssonload)}};lsloader.runjs=function(path,name,code){if(!!name&&!!code){for(var k in this.jsRunSequence){if(this.jsRunSequence[k].name==name){this.jsRunSequence[k].code=code}}}if(!!this.jsRunSequence[0]&&!!this.jsRunSequence[0].code&&this.jsRunSequence[0].status!="failed"){var script=document.createElement("script");script.appendChild(document.createTextNode(this.jsRunSequence[0].code));script.type="text/javascript";document.getElementsByTagName("head")[0].appendChild(script);this.jsRunSequence.shift();if(this.jsRunSequence.length>0){this.runjs()}}else if(!!this.jsRunSequence[0]&&this.jsRunSequence[0].status=="failed"){var that=this;var script=document.createElement("script");script.src=this.jsRunSequence[0].path;script.type="text/javascript";this.jsRunSequence[0].status="loading";script.onload=function(){that.jsRunSequence.shift();if(that.jsRunSequence.length>0){that.runjs()}};document.body.appendChild(script)}};lsloader.tagLoad=function(path,name){this.jsRunSequence.push({name:name,code:"",path:path,status:"failed"});this.runjs()};lsloader.jsfallback=function(path,name){if(!!this.jsnamemap[name]){return}else{this.jsnamemap[name]=name}for(var k in this.jsRunSequence){if(this.jsRunSequence[k].name==name){this.jsRunSequence[k].code="";this.jsRunSequence[k].status="failed";this.jsRunSequence[k].path=path}}this.runjs()};lsloader.cssfallback=function(path,name,cssonload){if(!!this.cssnamemap[name]){return}else{this.cssnamemap[name]=1}var link=document.createElement("link");link.type="text/css";link.href=path;link.rel="stylesheet";link.onload=link.onerror=cssonload;var root=document.getElementsByTagName("script")[0];root.parentNode.insertBefore(link,root)};lsloader.runInlineScript=function(scriptId,codeId){var code=document.getElementById(codeId).innerText;this.jsRunSequence.push({name:scriptId,code:code});this.runjs()};lsloader.loadCombo=function(jslist){var updateList="";var requestingModules={};for(var k in jslist){var LS=this.getLS(jslist[k].name);if(!!LS){var version=LS.split(versionString)[0];var code=LS.split(versionString)[1]}else{var version=""}if(version==jslist[k].path){this.jsRunSequence.push({name:jslist[k].name,code:code,path:jslist[k].path})}else{this.jsRunSequence.push({name:jslist[k].name,code:null,path:jslist[k].path,status:"comboloading"});requestingModules[jslist[k].name]=true;updateList+=(updateList==""?"":";")+jslist[k].path}}var that=this;if(!!updateList){var xhr=new XMLHttpRequest;xhr.open("get",combo+updateList,true);xhr.onreadystatechange=function(){if(xhr.readyState==4){if(xhr.status>=200&&xhr.status<300||xhr.status==304){if(xhr.response!=""){that.runCombo(xhr.response,requestingModules);return}}else{for(var i in that.jsRunSequence){if(requestingModules[that.jsRunSequence[i].name]){that.jsRunSequence[i].status="failed"}}that.runjs()}}};xhr.send(null)}this.runjs()};lsloader.runCombo=function(comboCode,requestingModules){comboCode=comboCode.split("/*combojs*/");comboCode.shift();for(var k in this.jsRunSequence){if(!!requestingModules[this.jsRunSequence[k].name]&&!!comboCode[0]){this.jsRunSequence[k].status="comboJS";this.jsRunSequence[k].code=comboCode[0];this.setLS(this.jsRunSequence[k].name,this.jsRunSequence[k].path+versionString+comboCode[0]);comboCode.shift()}}this.runjs()}})();</script>

    <!-- Import queue -->
    <script>function Queue(){this.dataStore=[];this.offer=b;this.poll=d;this.execNext=a;this.debug=false;this.startDebug=c;function b(e){if(this.debug){console.log("Offered a Queued Function.")}if(typeof e==="function"){this.dataStore.push(e)}else{console.log("You must offer a function.")}}function d(){if(this.debug){console.log("Polled a Queued Function.")}return this.dataStore.shift()}function a(){var e=this.poll();if(e!==undefined){if(this.debug){console.log("Run a Queued Function.")}e()}}function c(){this.debug=true}}var queue=new Queue();</script>

    <!-- Favicons -->
    <link rel="icon shortcut" type="image/ico" href="/img/favicon.png">
    <link rel="icon" sizes="192x192" href="/img/favicon.png">
    <link rel="apple-touch-icon" href="/img/favicon.png">

    <!--iOS -->
    <meta name="apple-mobile-web-app-title" content="Title">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <meta name="HandheldFriendly" content="True">
    <meta name="MobileOptimized" content="480">

    <!-- Add to homescreen for Chrome on Android -->
    <meta name="mobile-web-app-capable" content="yes">

    <!-- Add to homescreen for Safari on iOS -->
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <meta name="apple-mobile-web-app-title" content="Azurery">

    <!-- Site Verification -->
    
    

    <!-- RSS -->
    

    <!--[if lte IE 9]>
        <link rel="stylesheet" href="/css/ie-blocker.css">

        
            <script src="/js/ie-blocker.zhCN.js"></script>
        
    <![endif]-->

    <!-- Import CSS -->
    
        <style id="material_css"></style><script>if(typeof window.lsLoadCSSMaxNums === "undefined")window.lsLoadCSSMaxNums = 0;window.lsLoadCSSMaxNums++;lsloader.load("material_css","/css/material.min.css?Z7a72R1E4SxzBKR/WGctOA==",function(){if(typeof window.lsLoadCSSNums === "undefined")window.lsLoadCSSNums = 0;window.lsLoadCSSNums++;if(window.lsLoadCSSNums == window.lsLoadCSSMaxNums)document.documentElement.style.display="";}, false)</script>
        <style id="style_css"></style><script>if(typeof window.lsLoadCSSMaxNums === "undefined")window.lsLoadCSSMaxNums = 0;window.lsLoadCSSMaxNums++;lsloader.load("style_css","/css/style.min.css?MKetZV3cUTfDxvMffaOezg==",function(){if(typeof window.lsLoadCSSNums === "undefined")window.lsLoadCSSNums = 0;window.lsLoadCSSNums++;if(window.lsLoadCSSNums == window.lsLoadCSSMaxNums)document.documentElement.style.display="";}, false)</script>

        
            
                <style id="prettify_css"></style><script>if(typeof window.lsLoadCSSMaxNums === "undefined")window.lsLoadCSSMaxNums = 0;window.lsLoadCSSMaxNums++;lsloader.load("prettify_css","/css/prettify.min.css?zp8STOU9v89XWFEnN+6YmQ==",function(){if(typeof window.lsLoadCSSNums === "undefined")window.lsLoadCSSNums = 0;window.lsLoadCSSNums++;if(window.lsLoadCSSNums == window.lsLoadCSSMaxNums)document.documentElement.style.display="";}, false)</script>
                <style id="prettify_theme"></style><script>if(typeof window.lsLoadCSSMaxNums === "undefined")window.lsLoadCSSMaxNums = 0;window.lsLoadCSSMaxNums++;lsloader.load("prettify_theme","/css/prettify/vibrant-ink.min.css?e5E/qqGcGveS7VTH4M896w==",function(){if(typeof window.lsLoadCSSNums === "undefined")window.lsLoadCSSNums = 0;window.lsLoadCSSNums++;if(window.lsLoadCSSNums == window.lsLoadCSSMaxNums)document.documentElement.style.display="";}, false)</script>
            
        

    

    

    <!-- Config CSS -->

<!-- Other Styles -->
<style>
  body, html {
    font-family: Roboto, "Helvetica Neue", Helvetica, "PingFang SC", "Hiragino Sans GB", "Microsoft YaHei", "微软雅黑", Arial, sans-serif;
    overflow-x: hidden !important;
  }
  
  code {
    font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
  }

  a {
    color: #00838F;
  }

  .mdl-card__media,
  #search-label,
  #search-form-label:after,
  #scheme-Paradox .hot_tags-count,
  #scheme-Paradox .sidebar_archives-count,
  #scheme-Paradox .sidebar-colored .sidebar-header,
  #scheme-Paradox .sidebar-colored .sidebar-badge{
    background-color: #0097A7 !important;
  }

  /* Sidebar User Drop Down Menu Text Color */
  #scheme-Paradox .sidebar-colored .sidebar-nav>.dropdown>.dropdown-menu>li>a:hover,
  #scheme-Paradox .sidebar-colored .sidebar-nav>.dropdown>.dropdown-menu>li>a:focus {
    color: #0097A7 !important;
  }

  #post_entry-right-info,
  .sidebar-colored .sidebar-nav li:hover > a,
  .sidebar-colored .sidebar-nav li:hover > a i,
  .sidebar-colored .sidebar-nav li > a:hover,
  .sidebar-colored .sidebar-nav li > a:hover i,
  .sidebar-colored .sidebar-nav li > a:focus i,
  .sidebar-colored .sidebar-nav > .open > a,
  .sidebar-colored .sidebar-nav > .open > a:hover,
  .sidebar-colored .sidebar-nav > .open > a:focus,
  #ds-reset #ds-ctx .ds-ctx-entry .ds-ctx-head a {
    color: #0097A7 !important;
  }

  .toTop {
    background: #757575 !important;
  }

  .material-layout .material-post>.material-nav,
  .material-layout .material-index>.material-nav,
  .material-nav a {
    color: #757575;
  }

  #scheme-Paradox .MD-burger-layer {
    background-color: #757575;
  }

  #scheme-Paradox #post-toc-trigger-btn {
    color: #757575;
  }

  .post-toc a:hover {
    color: #00838F;
    text-decoration: underline;
  }

</style>


<!-- Theme Background Related-->

    <style>
      body{
        background-image: url(/img/bg.png);
      }
    </style>




<!-- Fade Effect -->

    <style>
      .fade {
        transition: all 800ms linear;
        -webkit-transform: translate3d(0,0,0);
        -moz-transform: translate3d(0,0,0);
        -ms-transform: translate3d(0,0,0);
        -o-transform: translate3d(0,0,0);
        transform: translate3d(0,0,0);
        opacity: 1;
      }

      .fade.out{
        opacity: 0;
      }
    </style>


<!-- Import Font -->
<!-- Import Roboto -->

    <link href="https://fonts.googleapis.com/css?family=Roboto:300,400,500" rel="stylesheet">


<!-- Import Material Icon -->

    <link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">




    <!-- Import jQuery -->
    
        <script>lsloader.load("jq_js","/js/jquery.min.js?qcusAULNeBksqffqUM2+Ig==", true)</script>
    

    <!-- The Open Graph protocol -->
    <meta property="og:url" content="http://yoursite.com">
    <meta property="og:type" content="blog">
    <meta property="og:title" content="CNN | Azurery">
    <meta property="og:image" content="http://yoursite.com/img/favicon.png" />
    <meta property="og:description" content="蒟蒻一枚">
    <meta property="og:article:tag" content="DL"> 

    
        <meta property="article:published_time" content="Sat Nov 10 2018 21:22:36 GMT+0800" />
        <meta property="article:modified_time" content="Sun Dec 30 2018 11:56:53 GMT+0800" />
    

    <!-- The Twitter Card protocol -->
    <meta name="twitter:title" content="CNN | Azurery">
    <meta name="twitter:description" content="蒟蒻一枚">
    <meta name="twitter:image" content="http://yoursite.com/img/favicon.png">
    <meta name="twitter:card" content="summary_large_image" />
    <meta name="twitter:url" content="http://yoursite.com" />

    <!-- Add canonical link for SEO -->
    
        <link rel="canonical" href="http://yoursite.com/2018/11/10/CNN/index.html" />
    

    <!-- Structured-data for SEO -->
    
        


<script type="application/ld+json">
{
    "@context": "https://schema.org",
    "@type": "BlogPosting",
    "mainEntityOfPage": "http://yoursite.com/2018/11/10/CNN/index.html",
    "headline": "CNN",
    "datePublished": "Sat Nov 10 2018 21:22:36 GMT+0800",
    "dateModified": "Sun Dec 30 2018 11:56:53 GMT+0800",
    "author": {
        "@type": "Person",
        "name": "Magicmanoooo",
        "image": {
            "@type": "ImageObject",
            "url": "/img/avatar.png"
        },
        "description": "秘境，探寻你的足迹"
    },
    "publisher": {
        "@type": "Organization",
        "name": "Azurery",
        "logo": {
            "@type":"ImageObject",
            "url": "/img/favicon.png"
        }
    },
    "keywords": ",DL",
    "description": "蒟蒻一枚",
}
</script>


    

    <!-- Analytics -->
    
    
    

    <!-- Custom Head -->
    

</head>


    
        <body id="scheme-Paradox" class="lazy">
            <div class="material-layout  mdl-js-layout has-drawer is-upgraded">
                

                <!-- Main Container -->
                <main class="material-layout__content" id="main">

                    <!-- Top Anchor -->
                    <div id="top"></div>

                    
                        <!-- Hamburger Button -->
                        <button class="MD-burger-icon sidebar-toggle">
                            <span class="MD-burger-layer"></span>
                        </button>
                    

                    <!-- Post TOC -->

    
    <!-- Back Button -->
    <!--
    <div class="material-back" id="backhome-div" tabindex="0">
        <a class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--icon"
           href="#" onclick="window.history.back();return false;"
           target="_self"
           role="button"
           data-upgraded=",MaterialButton,MaterialRipple">
            <i class="material-icons" role="presentation">arrow_back</i>
            <span class="mdl-button__ripple-container">
                <span class="mdl-ripple"></span>
            </span>
        </a>
    </div>
    -->


    <!-- Left aligned menu below button -->
    
    
    <button id="post-toc-trigger-btn"
        class="mdl-button mdl-js-button mdl-button--icon">
        <i class="material-icons">format_list_numbered</i>
    </button>

    <ul class="post-toc-wrap mdl-menu mdl-menu--bottom-left mdl-js-menu mdl-js-ripple-effect" for="post-toc-trigger-btn" style="max-height:80vh; overflow-y:scroll;">
        <ol class="post-toc"><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#神经网络基础概念"><span class="post-toc-number">1.</span> <span class="post-toc-text">神经网络基础概念</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#神经网络的工作原理"><span class="post-toc-number">1.1.</span> <span class="post-toc-text">神经网络的工作原理</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#损失函数（loss-function）"><span class="post-toc-number">1.2.</span> <span class="post-toc-text">损失函数（loss function）</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#优化器（optimizer）"><span class="post-toc-number">1.3.</span> <span class="post-toc-text">优化器（optimizer）</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#神经网络的组件"><span class="post-toc-number">1.4.</span> <span class="post-toc-text">神经网络的组件</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#神经网络的数据表示"><span class="post-toc-number">1.5.</span> <span class="post-toc-text">神经网络的数据表示</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#张量的关键属性有以下三个关键属性来定义："><span class="post-toc-number">1.5.1.</span> <span class="post-toc-text">张量的关键属性有以下三个关键属性来定义：</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#梯度"><span class="post-toc-number">1.5.2.</span> <span class="post-toc-text">梯度</span></a></li></ol></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#训练网络"><span class="post-toc-number">1.6.</span> <span class="post-toc-text">训练网络</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#为什么需要激活函数？"><span class="post-toc-number">1.7.</span> <span class="post-toc-text">为什么需要激活函数？</span></a></li></ol></li><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#交叉熵"><span class="post-toc-number">2.</span> <span class="post-toc-text">交叉熵</span></a></li><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#基础知识"><span class="post-toc-number">3.</span> <span class="post-toc-text">基础知识</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#无监督预训练（Unsupervised-pre-training）"><span class="post-toc-number">3.1.</span> <span class="post-toc-text">无监督预训练（Unsupervised pre-training）</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#有监督预训练（Supervised-pre-training）"><span class="post-toc-number">3.2.</span> <span class="post-toc-text">有监督预训练（Supervised pre-training）</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#IoU"><span class="post-toc-number">3.3.</span> <span class="post-toc-text">IoU</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#非极大值抑制"><span class="post-toc-number">3.4.</span> <span class="post-toc-text">非极大值抑制</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#对梯度幅值进行非极大值抑制"><span class="post-toc-number">3.5.</span> <span class="post-toc-text">对梯度幅值进行非极大值抑制</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#物体检测-VS-图片分类"><span class="post-toc-number">3.6.</span> <span class="post-toc-text">物体检测 VS 图片分类</span></a></li></ol></li><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#Selective-Search-for-Object-Recognition"><span class="post-toc-number">4.</span> <span class="post-toc-text">Selective Search for Object Recognition</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#目标检测-VS-目标识别"><span class="post-toc-number">4.1.</span> <span class="post-toc-text">目标检测 VS 目标识别</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#Sliding-Window-Algorithm"><span class="post-toc-number">4.2.</span> <span class="post-toc-text">Sliding Window Algorithm</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#Region-Proposal-Algorithms"><span class="post-toc-number">4.3.</span> <span class="post-toc-text">Region Proposal Algorithms</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#Selective-Search"><span class="post-toc-number">4.4.</span> <span class="post-toc-text">Selective Search</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#算法流程："><span class="post-toc-number">4.4.1.</span> <span class="post-toc-text">算法流程：</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#相似度计算"><span class="post-toc-number">4.4.2.</span> <span class="post-toc-text">相似度计算</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#颜色相似度（color-similarity）"><span class="post-toc-number">4.4.2.1.</span> <span class="post-toc-text">颜色相似度（color similarity）</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#纹理相似度（texture-similarity）"><span class="post-toc-number">4.4.2.2.</span> <span class="post-toc-text">纹理相似度（texture similarity）</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#尺寸相似度（size-similarity）"><span class="post-toc-number">4.4.2.3.</span> <span class="post-toc-text">尺寸相似度（size similarity）</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#交叠相似度（shape-compatibility-measure）"><span class="post-toc-number">4.4.2.4.</span> <span class="post-toc-text">交叠相似度（shape compatibility measure）</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#最终的相似度"><span class="post-toc-number">4.4.2.5.</span> <span class="post-toc-text">最终的相似度</span></a></li></ol></li></ol></li></ol></li><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#LeNet"><span class="post-toc-number">5.</span> <span class="post-toc-text">LeNet</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#第一层：卷积层"><span class="post-toc-number">5.1.</span> <span class="post-toc-text">第一层：卷积层</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#第二层：池化层"><span class="post-toc-number">5.2.</span> <span class="post-toc-text">第二层：池化层</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#第三层：卷积层"><span class="post-toc-number">5.3.</span> <span class="post-toc-text">第三层：卷积层</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#第四层：池化层"><span class="post-toc-number">5.4.</span> <span class="post-toc-text">第四层：池化层</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#第五层：全连接层"><span class="post-toc-number">5.5.</span> <span class="post-toc-text">第五层：全连接层</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#第六层：全连接层"><span class="post-toc-number">5.6.</span> <span class="post-toc-text">第六层：全连接层</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#第七层：全连接层"><span class="post-toc-number">5.7.</span> <span class="post-toc-text">第七层：全连接层</span></a></li></ol></li><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#RCNN"><span class="post-toc-number">6.</span> <span class="post-toc-text">RCNN</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#整体过程："><span class="post-toc-number">6.1.</span> <span class="post-toc-text">整体过程：</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#1-算法的整体思路"><span class="post-toc-number">6.2.</span> <span class="post-toc-text">1. 算法的整体思路</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#2-候选框的搜索"><span class="post-toc-number">6.3.</span> <span class="post-toc-text">2. 候选框的搜索</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#各向异性缩放"><span class="post-toc-number">6.3.1.</span> <span class="post-toc-text">各向异性缩放</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#各向同性缩放"><span class="post-toc-number">6.3.2.</span> <span class="post-toc-text">各向同性缩放</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#非极大值抑制的具体操作"><span class="post-toc-number">6.3.3.</span> <span class="post-toc-text">非极大值抑制的具体操作</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#步骤："><span class="post-toc-number">6.3.3.1.</span> <span class="post-toc-text">步骤：</span></a></li></ol></li></ol></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#3-CNN特征提取"><span class="post-toc-number">6.4.</span> <span class="post-toc-text">3. CNN特征提取</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#1-网络结构设计"><span class="post-toc-number">6.4.1.</span> <span class="post-toc-text">1. 网络结构设计</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#2-有监督预训练"><span class="post-toc-number">6.4.2.</span> <span class="post-toc-text">2. 有监督预训练</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#3-fine-tuning训练"><span class="post-toc-number">6.4.3.</span> <span class="post-toc-text">3. fine-tuning训练</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#疑问"><span class="post-toc-number">6.4.4.</span> <span class="post-toc-text">疑问</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#1-既然CNN都是用于提取特征，那么直接用Alexnet做特征提取，省去fine-tuning阶段可以吗？"><span class="post-toc-number">6.4.4.1.</span> <span class="post-toc-text">1. 既然CNN都是用于提取特征，那么直接用Alexnet做特征提取，省去fine-tuning阶段可以吗？</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#2-没有fine-tuning的时候，要选择哪一层的特征作为CNN提取到的特征呢？由于可以选择p5、f6、f7，这三层的神经元个数分别是9216、4096、4096。从p5到p6这层的参数个数是：4096-9216，从f6到f7的参数是4096-4096。那么具体是选择p5、f6还是f7呢？"><span class="post-toc-number">6.4.4.2.</span> <span class="post-toc-text">2. 没有fine-tuning的时候，要选择哪一层的特征作为CNN提取到的特征呢？由于可以选择p5、f6、f7，这三层的神经元个数分别是9216、4096、4096。从p5到p6这层的参数个数是：4096*9216，从f6到f7的参数是4096*4096。那么具体是选择p5、f6还是f7呢？</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#3-CNN在进行训练的时候，本来就是对bounding-box的物体进行识别分类训练，是一个端到端的任务。在训练的最后一层softmax就是分类层，那么为什么要先用CNN做特征提取（提取fc7层数据），然后再把提取的特征用于训练SVM分类器？"><span class="post-toc-number">6.4.4.3.</span> <span class="post-toc-text">3. CNN在进行训练的时候，本来就是对bounding box的物体进行识别分类训练，是一个端到端的任务。在训练的最后一层softmax就是分类层，那么为什么要先用CNN做特征提取（提取fc7层数据），然后再把提取的特征用于训练SVM分类器？</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#4-为什么需要回归器？"><span class="post-toc-number">6.4.4.4.</span> <span class="post-toc-text">4. 为什么需要回归器？</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#如何设计回归器（Bounding-box-regression）？"><span class="post-toc-number">6.4.4.5.</span> <span class="post-toc-text">如何设计回归器（Bounding-box regression）？</span></a></li></ol></li></ol></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#4-SVM训练"><span class="post-toc-number">6.5.</span> <span class="post-toc-text">4. SVM训练</span></a></li></ol></li><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#AlexNet"><span class="post-toc-number">7.</span> <span class="post-toc-text">AlexNet</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#1-模型结构"><span class="post-toc-number">7.1.</span> <span class="post-toc-text">1. 模型结构</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#2-创新点"><span class="post-toc-number">7.2.</span> <span class="post-toc-text">2. 创新点</span></a></li></ol></li><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#Fast-RCNN"><span class="post-toc-number">8.</span> <span class="post-toc-text">Fast RCNN</span></a></li></ol>
    </ul>
    




<!-- Layouts -->

    <!-- Post Module -->
    <div class="material-post_container">

        <div class="material-post mdl-grid">
            <div class="mdl-card mdl-shadow--4dp mdl-cell mdl-cell--12-col">

                <!-- Post Header(Thumbnail & Title) -->
                
    <!-- Paradox Post Header -->
    
        
            <!-- Random Thumbnail -->
            <div class="post_thumbnail-random mdl-card__media mdl-color-text--grey-50">
            <script type="text/ls-javascript" id="post-thumbnail-script">
    var randomNum = Math.floor(Math.random() * 19 + 1);

    $('.post_thumbnail-random').attr('data-original', '/img/random/material-' + randomNum + '.png');
    $('.post_thumbnail-random').addClass('lazy');
</script>

        
    
            <p class="article-headline-p">
                CNN
            </p>
        </div>





                
                    <!-- Paradox Post Info -->
                    <div class="mdl-color-text--grey-700 mdl-card__supporting-text meta">

    <!-- Author Avatar -->
    <div id="author-avatar">
        <img src="/img/avatar.png" width="44px" height="44px" alt="Author Avatar"/>
    </div>
    <!-- Author Name & Date -->
    <div>
        <strong>Magicmanoooo</strong>
        <span>11月 10, 2018</span>
    </div>

    <div class="section-spacer"></div>

    <!-- Favorite -->
    <!--
        <button id="article-functions-like-button" class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--icon btn-like">
            <i class="material-icons" role="presentation">favorite</i>
            <span class="visuallyhidden">favorites</span>
        </button>
    -->

    <!-- Qrcode -->
    
        <button id="article-functions-qrcode-button" class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--icon">
    <i class="material-icons" role="presentation">devices other</i>
    <span class="visuallyhidden">devices other</span>
</button>
<ul class="mdl-menu mdl-menu--bottom-right mdl-js-menu mdl-js-ripple-effect" for="article-functions-qrcode-button">
    <li class="mdl-menu__item">在其它设备中阅读本文章</li>
    
        <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAN4AAADeCAAAAAB3DOFrAAACaUlEQVR42u3aQYrDMAwF0N7/0jPbgSHulxS7obysSgmxnxe2+dLr56ufFx4eHh4eHh4e3sN4r/j5//7Vd/7+czmJ5Si9ueHh4eGd5L3ZaoOJJsj1klXHvXoHDw8P7ySvOnx1018fM1cHQ3VueHh4eE/jVbf1q6mvL+h4eHh438pbb+X5P8mbeHh4eM/k5XFDMnwy3cdlLXh4eHgxrxofnPz9gfoeHh4e3pJXbmkqRrq9SY9miIeHh7eZ14tQJ81SvWOpEH/g4eHhHeflLVbrf96Era3WqxvaVfHw8PDGvGSwfKK9GLfaavBmOfDw8PA28/a1Q62PloTaC0fw8PDwTvKSyCA/DKrgvBjWjHHx8PDwbuL1qNVrd3KETK7ReHh4eCd5eXNVHhbcFeP2mgzw8PDwzvOSDbrXXlD9Qh6O4OHh4Z3nTa7C1VC497XCFRwPDw/vCG8ev84XorfQUQEMDw8P71beZFufBLvVC3dhCfDw8PA28/LyUrXAf1djwXo+5aYrPDw8vA28efw6bwJIlgMPDw/vCbxqwakaH+RFr1FrFx4eHt5m3jyWrW7f1e9U2wjw8PDwTvKSy24+/OTiPmpTwMPDw9vM623B+eR671Tbs/Dw8PBO8nplp+qBUY2DRxduPDw8vM286qbcK5JVY9885iife3h4eHg38eaHQb7R5+WuajMBHh4e3nleXsivtk/lyzePJPDw8PCexksOgySkmB8Y5Ss1Hh4e3kd5veGrU7+tvoeHh4e3jTe5FvcuxL2AGA8PD+8JvGoBrHdRnrRYJYcTHh4e3hne9z14eHh4eHh4eHgPeH4BZRK/g8ZDPWwAAAAASUVORK5CYII=">
    
</ul>

    

    <!-- Tags (bookmark) -->
    
    <button id="article-functions-viewtags-button" class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--icon">
        <i class="material-icons" role="presentation">bookmark</i>
        <span class="visuallyhidden">bookmark</span>
    </button>
    <ul class="mdl-menu mdl-menu--bottom-right mdl-js-menu mdl-js-ripple-effect" for="article-functions-viewtags-button">
        <li class="mdl-menu__item">
        <a class="post_tag-link" href="/tags/DL/">DL</a>
    </ul>
    

    <!-- Share -->
    <button id="article-fuctions-share-button" class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--icon">
    <i class="material-icons" role="presentation">share</i>
    <span class="visuallyhidden">share</span>
</button>
<ul class="mdl-menu mdl-menu--bottom-right mdl-js-menu mdl-js-ripple-effect" for="article-fuctions-share-button">
    

    

    <!-- Share Weibo -->
    
        <a class="post_share-link" href="http://service.weibo.com/share/share.php?appkey=&title=CNN&url=http://yoursite.com/2018/11/10/CNN/index.html&pic=http://yoursite.com/img/favicon.png&searchPic=false&style=simple" target="_blank">
            <li class="mdl-menu__item">
                分享到微博
            </li>
        </a>
    

    <!-- Share Twitter -->
    
        <a class="post_share-link" href="https://twitter.com/intent/tweet?text=CNN&url=http://yoursite.com/2018/11/10/CNN/index.html&via=Magicmanoooo" target="_blank">
            <li class="mdl-menu__item">
                分享到 Twitter
            </li>
        </a>
    

    <!-- Share Facebook -->
    
        <a class="post_share-link" href="https://www.facebook.com/sharer/sharer.php?u=http://yoursite.com/2018/11/10/CNN/index.html" target="_blank">
            <li class="mdl-menu__item">
                分享到 Facebook
            </li>
        </a>
    

    <!-- Share Google+ -->
    
        <a class="post_share-link" href="https://plus.google.com/share?url=http://yoursite.com/2018/11/10/CNN/index.html" target="_blank">
            <li class="mdl-menu__item">
                分享到 Google+
            </li>
        </a>
    

    <!-- Share LinkedIn -->
    

    <!-- Share QQ -->
    
        <a class="post_share-link" href="http://connect.qq.com/widget/shareqq/index.html?site=Azurery&title=CNN&summary=蒟蒻一枚&pics=http://yoursite.com/img/favicon.png&url=http://yoursite.com/2018/11/10/CNN/index.html" target="_blank">
            <li class="mdl-menu__item">
                分享到 QQ
            </li>
        </a>
    

    <!-- Share Telegram -->
    
</ul>

</div>

                

                <!-- Post Content -->
                <div id="post-content" class="mdl-color-text--grey-700 mdl-card__supporting-text fade out">
    
        <p>深度学习以数据的原始形态（raw data）作为算法的输入，经过算法的层层抽象，将原始数据逐层抽象为自身任务所需的最终特种表示，最后以特征到任务的目标的映射（mapping）作为结束，从原始数据到最终任务目标，一气呵成而中间并无夹杂任何人为操作。相比于传统的ML算法仅学得模型这一单一任务模块而言，DL除了模型学习，还有特征学习、特征抽象等任务模块的参与，借助多层任务模块完成最终的学习任务。</p>
<h1 id="神经网络基础概念"><a href="#神经网络基础概念" class="headerlink" title="神经网络基础概念"></a>神经网络基础概念</h1><h2 id="神经网络的工作原理"><a href="#神经网络的工作原理" class="headerlink" title="神经网络的工作原理"></a>神经网络的工作原理</h2><p>神经网络中每层对输入数据所做的具体操作保存在该层的权重（ weight）中，其本质是一串数字。用术语来说，每层实现的变换由其权重来参数化（ parameterize）。权重有时也被称为该层的参数（ parameter）。在这种语境下，<strong>学习的意思是为神经网络的所有层找到一组权重值，使得该网络能够将每个示例输入与其目标正确地一一对应</strong>。</p>
<p>一个深度神经网络可能包含数千万个参数。找到所有参数的正确取值可能是一项非常艰巨的任务，特别是考虑到修改某个参数值将会影响其他所有参数的行为。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/1351548-19d814df9cde4e2d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p>
<h2 id="损失函数（loss-function）"><a href="#损失函数（loss-function）" class="headerlink" title="损失函数（loss function）"></a>损失函数（loss function）</h2><p><strong>想要控制神经网络的输出，就需要能够衡量该输出与预期值之间的距离</strong>。这是神经网络损失函数（ loss function）的任务，该函数也叫目标函数（ objective function）。<strong>损失函数的输入是网络预测值与真实目标值（即希望网络输出的结果），然后计算一个距离值，衡量该网络在这个示例上的效果好坏</strong>。简而言之，损失函数用于网络如何衡量在训练数据上的性能，即网络如何朝着正确的方向前进。在训练过程中需要将其最小化。它能够衡量当前任务是否已成功完成。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/1351548-652baf565ef24a2b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p>
<h2 id="优化器（optimizer）"><a href="#优化器（optimizer）" class="headerlink" title="优化器（optimizer）"></a>优化器（optimizer）</h2><p>深度学习的基本技巧是：<strong>利用之前的距离值作为反馈信号来对权重值进行微调（fine tuning），以降低当前示例对应的损失值。这种调节由优化器（ optimizer）来完成，它实现了所谓的反向传播（ backpropagation）算法，这是深度学习的核心算法</strong>。其基于训练数据和损失函数来更新网络的机制。决定如何基于损失函数对网络进行更新。它执行的是随机梯度下降（ SGD）的某个变体。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/1351548-b4b7fa5551d1d28f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p>
<h2 id="神经网络的组件"><a href="#神经网络的组件" class="headerlink" title="神经网络的组件"></a>神经网络的组件</h2><p><strong>神经网络的核心组件是层（ layer），它是一种数据处理模块，可以将它看成数据 filter </strong>。进去一些数据，出来的数据变得更加有用。具体来说，层从输入数据中提取表示。大多数深度学习都是将简单的层链接起来，从而实现渐进式的数据蒸馏（ data distillation）。深度学习模型就像是数据处理的筛子，包含一系列越来越精细的数据 filter （即层）。有些层是无状态的，但大多数的层是有状态的，即层的权重。<strong>权重是利用随机梯度下降学到的一个或多个张量，其中包含网络的知识</strong>。</p>
<h2 id="神经网络的数据表示"><a href="#神经网络的数据表示" class="headerlink" title="神经网络的数据表示"></a>神经网络的数据表示</h2><p>张量的核心在于，它是一个<strong>数据容器</strong>。它包含的数据几乎总是数值数据，因此它是数字的容器。<strong>张量是矩阵向任意维度的推广</strong>［注意，张量的维度（ dimension）通常叫作轴（ axis）]</p>
<ul>
<li>仅包含一个数字的张量，叫作标量（ scalar）</li>
<li>数字组成的数组，叫作向量（ vector）或一维张量（ 1D 张量，一维张量只有一个轴）</li>
<li>向量组成的数组叫作矩阵（ matrix）或二维张量（ 2D 张量）。矩阵有 2 个轴（通常叫作行和列）。</li>
</ul>
<h3 id="张量的关键属性有以下三个关键属性来定义："><a href="#张量的关键属性有以下三个关键属性来定义：" class="headerlink" title="张量的关键属性有以下三个关键属性来定义："></a>张量的关键属性有以下三个关键属性来定义：</h3><ol>
<li>轴的个数（阶）</li>
<li>形状，它是一个整数元祖，表示张量沿每个轴的维度大小（元素大小）</li>
<li>数据类型（在Python库中通常叫做<code>dtype</code>）</li>
</ol>
<h3 id="梯度"><a href="#梯度" class="headerlink" title="梯度"></a>梯度</h3><p>每个神经层都用下述方法对输入数据进行变换。</p>
<pre><code class="python">output = relu(dot(W, input) + b)
</code></pre>
<p><code>W</code>和<code>b</code>都是张量，均为该层的属性。它们被称为该层的权重（ weight）或可训练参数（ trainable parameter），</p>
<p>一开始，这些权重矩阵取较小的随机值，这一步叫作随机初始化（ random initialization）。<code>W</code>和<code>b</code>都是随机的，<code>relu(dot(W, input) + b)</code>肯定不会得到任何有用的表示。虽然得到的表示是没有意义的，但这是一个起点。下一步则是根据反馈信号逐渐调节这些权重。这个逐渐调节的过程叫作<strong>训练</strong>，也就是机器学习中的<strong>学习</strong>。</p>
<p>上述过程发生在一个训练循环（ training loop）内，其具体过程如下（必要时一直重复这些步骤）：</p>
<ol>
<li>抽取训练样本<code>x</code>和对应目标<code>y</code>组成的数据批量</li>
<li>在<code>x</code>上运行网络（这一步叫作<strong>前向传播， forward pass</strong>），得到预测值<code>y_pred</code></li>
<li>计算网络在这批数据上的损失，用于衡量<code>y_pred</code>和<code>y</code>之间的距离</li>
<li>更新网络的所有权重，使网络在这批数据上的损失略微下降</li>
</ol>
<p>最终得到的网络在训练数据上的损失非常小，即预测值<code>y_pred</code>和预期目标<code>y</code>之间的距离非常小。网络“学会”将输入映射到正确的目标。</p>
<p>计算损失相对于网络系数的梯度（ gradient），然后向梯度<br>的反方向改变系数，从而使损失降低。</p>
<h2 id="训练网络"><a href="#训练网络" class="headerlink" title="训练网络"></a>训练网络</h2><p>一开始对神经网络的权重随机赋值，因此网络只是实现了一系列随机变换。其输出结果自然也和理想值相去甚远，相应地，损失值也很高。但随着网络处理的示例越来越多，权重值也在向正确的方向逐步微调，损失值也逐渐降低。这就是<strong>训练循环（ training loop）</strong>，将这种循环重复足够多的次数（通常对数千个示例进行数十次迭代），得到的权重值可以使损失函数最小。具有最小损失的网络，其输出值与目标值尽可能地接近，这就是训练好的网络。</p>
<p>典型的Keras工作流程：</p>
<ol>
<li>定义训练数据：输入张量和目标张量。</li>
<li>定义层组成的网络（或模型），将输入映射到目标。</li>
<li>配置学习过程：选择损失函数、优化器和需要监控的指标。</li>
<li>调用模型的<code>fit</code>方法在训练数据上进行迭代。</li>
</ol>
<p>Keras定义模型有两种方法：</p>
<ul>
<li>使用<code>Sequential</code>类（仅用于层的线性堆叠，这是目前最常见的网络架构）</li>
<li>函数式<code>API</code>（functional API，用于层组成的有向无环图，可以构建任意形式的架构）。</li>
</ul>
<h2 id="为什么需要激活函数？"><a href="#为什么需要激活函数？" class="headerlink" title="为什么需要激活函数？"></a>为什么需要激活函数？</h2><p>如果没有<code>relu</code>等激活函数（也叫<strong>非线性</strong>），<code>Dense</code>层将只包含两个线性运算——点积和加法：</p>
<pre><code class="python">Dense(16, activation=&#39;relu&#39;)
output = dot(W, input) + b
</code></pre>
<p>这将导致<code>Dense</code>层就<strong>只能学习输入数据的线性变换（仿射变换）：该层的假设空间是从输入数据到<code>16</code>位空间所有可能的线性变换集合</strong>。这种假设空间非常有限，无法利用多个表示层的优势，因为多个线性层堆叠实现的仍是线性运算，添加层数并不会扩展假设空间。</p>
<p>为了得到更丰富的假设空间，从而充分利用多层表示的优势，需要添加非线性或激活函数。 </p>
<h1 id="交叉熵"><a href="#交叉熵" class="headerlink" title="交叉熵"></a>交叉熵</h1><p>刻画了两个概率分布之间的距离，它是分类问题中使用比较广的一种损失函数。给定两个概率分布 <code>p</code> 和 <code>q</code> ， 通过 <code>q</code> 来表示 <code>p</code> 的交叉熵为 ：</p>
<p><img src="https://upload-images.jianshu.io/upload_images/1351548-d65fdc08cb1301b9.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p>
<p>交叉熵刻画的是两个概率分布之间的距离 ， 然而神经网络的输出却不一定是一个概率分布。概率分布刻画了不同事件发生的概率。当事件总数有限的情况下 ，概率分布函数 <img src="https://upload-images.jianshu.io/upload_images/1351548-aef4ae4834de9636.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""> 满足 ：</p>
<p><img src="https://upload-images.jianshu.io/upload_images/1351548-4aba17810c6147af.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""><br>也就是说，任意事件发生的概率都在 <code>0</code> 和 <code>1</code> 之间，且总有某一个事件发生 （概率的和为 <code>1</code> ）。如果将分类问题中“ 一个样例属于某一个类别”看成一个概率事件，那么训练数据的正确答案就符合一个概率分布。因为事件“一个样例属于不正确的类别”的概率为 <code>1</code>，而“ 一个样例属于正确的类别”的概率为 <code>1</code> 。如何将神经网络前向传播得到的结果也变成概率分布呢？ <code>Softmax</code> 回归就是一个非常常用的方法 。</p>
<p>在 TensorFlow 中，<code>Softmax</code> 回归的参数被去掉了，它只是一层额外的处理层，将神经网络的输出变成一个概率分布 。假设原始的神经网络输出为<img src="https://upload-images.jianshu.io/upload_images/1351548-b44113b7e9413800.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="">，那么经过 <code>Softmax</code> 回归处理之后的输出为 ：</p>
<p><img src="https://upload-images.jianshu.io/upload_images/1351548-7c98927906272ad0.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p>
<p>从以上公式中可以看出，原始神经网络的输出被用作置信度来生成新的输出，而新的输出满足概率分布的所有要求。这个新的输出可以理解为经过神经网络的推导，一个样例为不同类别的概率分别是多大。这样就把神经网络的输出也变成了一个概率分布，从而可以通过交叉熵来计算预测的概率分布和真实答案的概率分布之间的距离了。</p>
<p>从交叉熵的公式中可以看到，交叉熵函数不是对称（<img src="https://upload-images.jianshu.io/upload_images/1351548-0221c1bbb69f4c5c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="">），它刻画的是通过概率分布 <code>q</code> 来表达概率分布 <code>p</code> 的困难程度。因为正确答案是希望得到的结果，所以当交叉熵作为神经网络的损失函数时，<code>p</code> 代表的是正确答案，<code>q</code> 代表的是预测值。交叉熵刻画的是两个概率分布的距离，也就是说交叉熵值越小，两个概率分布越接近。</p>
<h1 id="基础知识"><a href="#基础知识" class="headerlink" title="基础知识"></a>基础知识</h1><h2 id="无监督预训练（Unsupervised-pre-training）"><a href="#无监督预训练（Unsupervised-pre-training）" class="headerlink" title="无监督预训练（Unsupervised pre-training）"></a>无监督预训练（Unsupervised pre-training）</h2><p>指预训练阶段的样本不需要人工标注数据</p>
<h2 id="有监督预训练（Supervised-pre-training）"><a href="#有监督预训练（Supervised-pre-training）" class="headerlink" title="有监督预训练（Supervised pre-training）"></a>有监督预训练（Supervised pre-training）</h2><p>也可以将其称为迁移学习。简而言之，就是<strong>把一个训练好的参数，拿到另外一个任务上，作为神经网络的初始参数值，这样就比直接采用随机初始化的方法的精度要提升很多</strong>。</p>
<p>例如，比如已经有一大堆标注好的人脸年龄分类的图片数据，训练了一个CNN，用于人脸的年龄识别。然后，当新的项目任务是：人脸性别识别时，便可以直接利用已经训练好的年龄识别CNN模型，去掉最后一层，然后其它的网络层参数就直接复制过来，继续进行训练。</p>
<h2 id="IoU"><a href="#IoU" class="headerlink" title="IoU"></a>IoU</h2><p><strong>物体检测需要定位出物体的bounding box</strong>。如下图所示，不仅要定位出车辆的bounding box，还需要识别出bounding box里面的物体就是车辆。对于bounding box的定位精度，存在一个定位精度评价公式：<code>IoU</code>（因为算法不可能百分百跟人工标注的数据完全匹配）。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/1351548-802c153951d23b3a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p>
<p><code>IoU</code>定义了两个bounding box的重叠度：</p>
<p><img src="https://upload-images.jianshu.io/upload_images/1351548-c66aff1ed95a2a1e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p>
<p>矩形框<code>A</code>、<code>B</code>的一个重合度<code>IoU</code>计算公式为：</p>
<p><img src="https://upload-images.jianshu.io/upload_images/1351548-1e77ae5572cea6de.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p>
<p>即，矩形框<code>A</code>、<code>B</code>的重叠面积占<code>A</code>、<code>B</code>并集的面积比例:</p>
<p><img src="https://upload-images.jianshu.io/upload_images/1351548-45bff28622a98ade.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p>
<h2 id="非极大值抑制"><a href="#非极大值抑制" class="headerlink" title="非极大值抑制"></a>非极大值抑制</h2><p>非极大值抑制（NMS）就是：<strong>抑制不是极大值的元素，搜索局部的极大值。这个局部代表的是一个邻域，邻域有两个参数可变，一是邻域的维数，二是邻域的大小</strong>。</p>
<p><strong>【注】：</strong>此处不讨论通用的<em>NMS</em>算法，而是应用于目标检测中用于提取分数最高的窗口。例如，在行人检测中，滑动窗口经提取特征，经分类器分类识别后，每个窗口都会得到一个分数。但滑动窗口会导致很多窗口与其他窗口存在包含或者大部分交叉的情况。这时就需要用到<em>NMS</em>来选取那些邻域里分数最高（即，行人的概率最大），并且抑制那些分数低的窗口。</p>
<p>RCNN算法会从一张图片中找出<code>n</code>多个可能是物体的矩形框，然后为每个矩形框分别作类别分类概率。</p>
<p>如下图所示，定位一个车辆，最后算法找出了一堆方框，需要判别哪些矩形框是没用的。非极大值抑制法的步骤：先假设有<code>6</code>个矩形框，根据分类器类别分类概率做排序，从小到大分别属于车辆的概率分别为<code>A</code>、<code>B</code>、<code>C</code>、<code>D</code>、<code>E</code>、<code>F</code>：</p>
<ol>
<li>从最大概率矩形框<code>F</code>开始，分别判断<code>A~E</code>与<code>F</code>的重叠度<code>IoU</code>是否大于某个设定的阈值。</li>
<li>假设<code>B</code>、<code>D</code>与<code>F</code>的重叠度超过阈值，则扔掉<code>B</code>、<code>D</code>；并标记第一个矩形框<code>F</code>是要保留下来的。</li>
<li>从剩下的矩形框<code>A</code>、<code>C</code>、<code>E</code>中，选择概率最大的<code>E</code>，然后判断<code>E</code>与<code>A</code>、<code>C</code>的重叠度<code>IoU</code>，重叠度大于一定的阈值就扔掉；并标记<code>E</code>是保留下来的第二个矩形框。</li>
</ol>
<p>一直重复，找到所有被保留下来的矩形框。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/1351548-81e3a20c58bf860a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p>
<h2 id="对梯度幅值进行非极大值抑制"><a href="#对梯度幅值进行非极大值抑制" class="headerlink" title="对梯度幅值进行非极大值抑制"></a>对梯度幅值进行非极大值抑制</h2><p>图像梯度幅值矩阵中的元素值越大，说明图像中该点的梯度值越大，但这不不能说明该点就是边缘（这仅仅是属于图像增强的过程）。在<em>Canny</em>算法中，非极大值抑制是进行边缘检测的重要步骤，通俗意义上是指：<strong>寻找像素点局部最大值，将非极大值点所对应的灰度值置为<code>0</code>，这样可以剔除掉一大部分非边缘的点</strong>。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/1351548-016aafd1cd753237.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p>
<p><strong>非极大值抑制的工作原理：</strong><br>由上图可知，要进行非极大值抑制，首先要确定像素点<code>C</code>的灰度值在其八邻域内是否为最大。蓝色线条方向为<code>C</code>点的梯度方向（这样就可以确定其局部的最大值肯定分布在这条线上），即除了<code>C</code>点外，梯度方向的交点<code>dTmp1</code>和<code>dTmp2</code>这两个点的值也可能会是局部最大值。</p>
<p>因此，判断<code>C</code>点灰度与这两个点灰度大小，即可判断<code>C</code>点是否为其邻域内的局部最大灰度点。如果经过判断，<code>C</code>点灰度值小于这两个点中的任一个，那就说明<code>C</code>点不是局部极大值，那么则可以排除<code>C</code>点为边缘。</p>
<p>在实际中，其实只能得到<code>C</code>点邻域的<code>8</code>个点的值，而<code>dTmp1</code>和<code>dTmp2</code>并不在其中。要得到这两个值，就需要对该两个点两端的已知灰度进行线性插值，即根据上图中的<code>g1</code>和<code>g2</code>对<code>dTmp1</code>进行插值，根据<code>g3</code>和<code>g4</code>对<code>dTmp2</code>进行插值，这要用到其梯度方向。</p>
<p>完成非极大值抑制后，会得到一个二值图像，非边缘的点灰度值均为<code>0</code>，可能为边缘的局部灰度极大值点可设置其灰度为<code>128</code>。</p>
<h2 id="物体检测-VS-图片分类"><a href="#物体检测-VS-图片分类" class="headerlink" title="物体检测 VS 图片分类"></a>物体检测 VS 图片分类</h2><p>物体检测和图片分类的区别：</p>
<ul>
<li>图片分类不需要定位，而物体检测需要定位出物体的位置，也就是相当于把物体的bbox检测出来。</li>
<li>物体检测是要把所有图片中的物体都识别定位出来。</li>
</ul>
<p>简言之，物体检测需要定位出物体的位置，这种就相当于回归问题，求解一个包含物体的方框。而图片分类其实是逻辑回归。这种方法对于单物体检测还不错，但是对于多物体检测便显得捉襟见肘。</p>
<h1 id="Selective-Search-for-Object-Recognition"><a href="#Selective-Search-for-Object-Recognition" class="headerlink" title="Selective Search for Object Recognition"></a>Selective Search for Object Recognition</h1><h2 id="目标检测-VS-目标识别"><a href="#目标检测-VS-目标识别" class="headerlink" title="目标检测 VS 目标识别"></a>目标检测 VS 目标识别</h2><ul>
<li>目标识别（object recognition）是指明一幅输入图像中存在哪些对象（目标）。它将整张图像作为输入，输出的是该图像中存在的对象（目标）的类标签（class labels）和类概率（class probability）。例如，类标签为“狗”，相关的类概率是<code>97％</code>。</li>
<li>目标检测（object detection）不仅要告诉输入图像中包含了哪类目标，还要框出该目标的具体位置—利用bounding boxes <code>(x, y, width, height)</code>来指示图像内对象的位置。</li>
</ul>
<p><img src="https://upload-images.jianshu.io/upload_images/1351548-8171190cdaa8253e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p>
<p><strong>所有的目标检测算法的核心是目标识别算法</strong>。在目标检测时，为了定位到目标的具体位置，通常会把图像分成许多子块（sub-regions / patches），然后把子块作为输入，送到目标识别的模型中。生成较小区域最直接方法叫滑动窗口法（Sliding Window Algorithm）。滑动窗口的方法就是按照子块的大小在整幅图像上穷举所有子图像块。这种方法产生的数据量想想都头大。和滑动窗口法相对的是另外一类基于区域（Region Proposal Algorithms）的方法，例如selective search。</p>
<h2 id="Sliding-Window-Algorithm"><a href="#Sliding-Window-Algorithm" class="headerlink" title="Sliding Window Algorithm"></a>Sliding Window Algorithm</h2><p>在滑动窗口方法中，在图像上滑动框或窗口以选择patch，并使用对象识别（object recognition）模型对窗口覆盖的每个图像patch进行分类。 它对整个图像上的对象进行详尽搜索：不仅需要搜索图像中的所有可能位置，还必须以不同的比例进行搜索（这是因为物体识别模型通常以特定尺度（或尺度范围）训练）。</p>
<p>滑窗法的物体检测流程图：<br><img src="https://upload-images.jianshu.io/upload_images/1351548-32cefc1fb88bbc7b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p>
<p>通过滑窗法的主要思路：首先对输入图像进行不同窗口大小的滑窗进行从左往右、从上到下的滑动。每次滑动时候，对当前窗口执行分类器(分类器是事先训练好的)。如果当前窗口得到较高的分类概率，则认为检测到了物体。对每个不同窗口大小的滑窗都进行检测后，会得到不同窗口检测到的物体标记，这些窗口大小会存在重复较高的部分，最后采用NMS进行筛选。最终，经过NMS筛选后获得检测到的物体。</p>
<p>滑窗法简单易于理解，但是不同窗口大小进行图像全局搜索导致效率低下，而且设计窗口大小时候还需要考虑物体的长宽比。所以，对于实时性要求较高的分类器，不推荐使用滑窗法。</p>
<p>滑动窗口方法适用于固定宽高比的物体，例如面部或行人。由于图像是<code>3D</code>对象的<code>2D</code>投影，所以宽高比和形状等对象特征会因为拍摄图像的角度而有很大差异。由于滑动窗口方法需要搜索多个宽高比，所以计算将十分耗时。</p>
<h2 id="Region-Proposal-Algorithms"><a href="#Region-Proposal-Algorithms" class="headerlink" title="Region Proposal Algorithms"></a>Region Proposal Algorithms</h2><p>这种方法将图像作为输入，将输出边bounding boxes—其对应于图像中最有可能为对象的所有patches。这些区域提议（region proposals）可能是嘈杂的（noisy）、重叠的（overlapping），并且可能没有完全包含对象。但是在这些区域提议中，将有一个非常接近图像中的实际对象的提议（proposal）。然后，可以使用目标识别模型对这些提议进行分类，具有高概率分数的区域提议是对象的位置。</p>
<p>区域提议算法使用分段（segmentation）识别图像中的预期对象。在分割中，基于一些标准（例如颜色，纹理等）将相邻区域进行分组。与在所有像素位置和所有尺度上寻找对象的sliding window approach不同，region proposal algorithm通过以下方式工作：将像素分成为较少数量的段（segments）。因此，生成的最终提案数量比滑动窗口方法少很多倍。这就减少了必须分类的图像patches的数量，这些生成的区域提议具有不同的比例和宽高比。</p>
<h2 id="Selective-Search"><a href="#Selective-Search" class="headerlink" title="Selective Search"></a>Selective Search</h2><p>选择搜索算法的主要观点：<strong>图像中物体可能存在的区域应该是有某些相似性或者连续性区域的。因此，选择搜索基于上面这一想法采用子区域合并的方法进行提取bounding boxes候选边界框。首先，对输入图像进行分割算法产生许多小的子区域。其次，根据这些子区域之间相似性(相似性标准主要有颜色、纹理、大小等等)进行区域合并，不断的进行区域迭代合并。每次迭代过程中对这些合并的子区域做bounding boxes(外切矩形)，这些子区域外切矩形就是通常所说的候选框。</strong></p>
<p>选择搜索的物体检测流程图：</p>
<p><img src="https://upload-images.jianshu.io/upload_images/1351548-a021478bbcff8416.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p>
<p>滑窗法类似穷举进行图像子区域搜索，但是一般情况下图像中大部分子区域是没有物体的。选择搜索算法的主要观点：<strong>图像中物体可能存在的区域应该是有某些相似性或者连续性区域的</strong>。因此，选择搜索基于这一想法，采用子区域合并的方法进行提取bounding boxes候选边界框。</p>
<ul>
<li>首先，对输入图像进行分割算法产生许多小的子区域。</li>
<li>其次，根据这些子区域之间相似性(相似性标准主要有颜色、纹理、大小等等)进行区域合并，不断的进行区域迭代合并。每次迭代过程中对这些合并的子区域做bounding boxes(外切矩形)，这些子区域外切矩形就是通常所说的候选框。</li>
</ul>
<h3 id="算法流程："><a href="#算法流程：" class="headerlink" title="算法流程："></a>算法流程：</h3><p><img src="https://upload-images.jianshu.io/upload_images/1351548-b02ebd1dc5e6639d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p>
<ul>
<li>step 0：生成区域集<code>R</code>，具体参见论文《Efficient Graph-Based Image Segmentation》</li>
<li>step 1：计算区域集<code>R</code>里每个相邻区域的相似度<code>S = {s1,s2,…}</code> </li>
<li>step 2：找出相似度最高的两个区域，将其合并为新集，添加进<code>R</code> </li>
<li>step 3：从<code>S</code>中移除所有与step 2中有关的子集 </li>
<li>step 4：计算新集与所有子集的相似度 </li>
<li>step 5：跳至step 2，直至<code>S</code>为空</li>
</ul>
<h3 id="相似度计算"><a href="#相似度计算" class="headerlink" title="相似度计算"></a>相似度计算</h3><p><a href="https://www.koen.me/research/pub/uijlings-ijcv2013-draft.pdf" target="_blank" rel="noopener">Selective Search for Object Recognition论文</a>考虑了颜色、纹理、尺寸和空间交叠这4个参数。</p>
<h4 id="颜色相似度（color-similarity）"><a href="#颜色相似度（color-similarity）" class="headerlink" title="颜色相似度（color similarity）"></a>颜色相似度（color similarity）</h4><p>将色彩空间转为<code>HSV</code>，对于每一个region的每个通道以<code>bins=25</code>计算直方图，这样每个区域的颜色直方图有<code>25*3=75</code>个区间。 对直方图除以区域尺寸做归一化后使用下式计算相似度：</p>
<p><img src="https://upload-images.jianshu.io/upload_images/1351548-eff1704538e4f10c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p>
<p>其中，<img src="https://upload-images.jianshu.io/upload_images/1351548-4e4cfa123e4817ae.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="">表示两个不同的region，<img src="https://upload-images.jianshu.io/upload_images/1351548-62e5b75b53d37959.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="">表示颜色直方图。</p>
<h4 id="纹理相似度（texture-similarity）"><a href="#纹理相似度（texture-similarity）" class="headerlink" title="纹理相似度（texture similarity）"></a>纹理相似度（texture similarity）</h4><p>采用方差为<code>1</code>（<img src="https://upload-images.jianshu.io/upload_images/1351548-3bf7bdb571fb795b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="">）的高斯分布在<code>8</code>个方向做梯度统计，然后将统计结果（尺寸与区域大小一致）以<code>bins=10</code>计算直方图。直方图区间数为<code>8*3*10=240</code>（使用RGB色彩空间）</p>
<p><img src="https://upload-images.jianshu.io/upload_images/1351548-8fcaf06f2a2cf2f8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p>
<p>其中，<img src="https://upload-images.jianshu.io/upload_images/1351548-1f7c99d38fc5d1f7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="">是直方图中第<img src="https://upload-images.jianshu.io/upload_images/1351548-a62871eb544528b6.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="">个<code>bin</code>的值</p>
<h4 id="尺寸相似度（size-similarity）"><a href="#尺寸相似度（size-similarity）" class="headerlink" title="尺寸相似度（size similarity）"></a>尺寸相似度（size similarity）</h4><p><img src="https://upload-images.jianshu.io/upload_images/1351548-72e9f09684e62525.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p>
<p>保证合并操作的尺度较为均匀，避免一个大区域陆续“吃掉”其他小区域。</p>
<p><strong>例子：</strong><br>设有区域<code>a-b-c-d-e-f-g-h</code>。</p>
<ul>
<li>较好的合并方式是：<code>ab-cd-ef-gh -&gt; abcd-efgh -&gt; abcdefgh</code>。 </li>
<li>不好的合并方法是：<code>ab-c-d-e-f-g-h -&gt;abcd-e-f-g-h -&gt;abcdef-gh -&gt; abcdefgh</code>。</li>
</ul>
<h4 id="交叠相似度（shape-compatibility-measure）"><a href="#交叠相似度（shape-compatibility-measure）" class="headerlink" title="交叠相似度（shape compatibility measure）"></a>交叠相似度（shape compatibility measure）</h4><p><img src="https://upload-images.jianshu.io/upload_images/1351548-db8f19304134fecf.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p>
<p><strong>例子：左图适于合并，右图不适于合并</strong></p>
<p><img src="https://upload-images.jianshu.io/upload_images/1351548-184f03ae37b03853.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p>
<h4 id="最终的相似度"><a href="#最终的相似度" class="headerlink" title="最终的相似度"></a>最终的相似度</h4><p><img src="https://upload-images.jianshu.io/upload_images/1351548-d3e553866a3762f1.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p>
<h1 id="LeNet"><a href="#LeNet" class="headerlink" title="LeNet"></a>LeNet</h1><p><img src="https://upload-images.jianshu.io/upload_images/1351548-47c319fa1b2e4308.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p>
<h2 id="第一层：卷积层"><a href="#第一层：卷积层" class="headerlink" title="第一层：卷积层"></a>第一层：卷积层</h2><p>这一层的输入就是原始的图像像素 ， LeNet 模型接受的输入层大小为 <code>32×32×l</code>。第一个卷积层 filter 的尺寸为 <code>5×5</code>，深度为 <code>6</code>，不使用全 <code>0</code> 填充，步长为 <code>1</code> 。因为没有使用全 <code>0</code> 填充，所以这 一 层的输出 的尺寸为 <code>32-5+1=28</code>， 深度为 <code>6</code> 。这一个卷积层总共有 <code>5×5×6+6=156</code> 个参数，其中 <code>6</code> 个为偏置项参数。因为下一层的节点矩阵有 <code>28×28=4704</code> 个节点，每个节点和 <code>5×5=25</code> 个当前层节点相连，所以本 层卷积层总共有 <code>4704×(25+1)=122304</code> 个连接。</p>
<h2 id="第二层：池化层"><a href="#第二层：池化层" class="headerlink" title="第二层：池化层"></a>第二层：池化层</h2><p>这一层的输入为第一层的输出， 是一个 <code>28×28×6</code> 的节点矩阵。本层采用的 filter 大小为 <code>2×2</code>，长和宽的步长均为 <code>2</code>，所以本层的输出矩阵大小为 <code>14×14×6</code>。</p>
<h2 id="第三层：卷积层"><a href="#第三层：卷积层" class="headerlink" title="第三层：卷积层"></a>第三层：卷积层</h2><p>本层的输入矩阵大小为 <code>14×14×6</code>，使用的 filter 大小为 <code>5×5</code> ，深度为 <code>16</code>。本层不使用全 <code>0</code> 填充， 步长为 <code>l</code>。本层的输出矩阵大小为 <code>10×10×16</code>。按照标准的卷积层 ，本层应该有 <code>5×5×6×16+16=2416</code> 个参数，<code>10×10×16×(25+1)=41600</code> 个连接。</p>
<h2 id="第四层：池化层"><a href="#第四层：池化层" class="headerlink" title="第四层：池化层"></a>第四层：池化层</h2><p>本层的输入矩阵大小为 <code>10×l0×16</code>，采用的 filter 大小为 <code>2×2</code>，步长为 <code>2</code>。本层的输出矩阵大小为 <code>5×5×l6</code>。</p>
<h2 id="第五层：全连接层"><a href="#第五层：全连接层" class="headerlink" title="第五层：全连接层"></a>第五层：全连接层</h2><p>本层的输入矩阵大小为 <code>5×5×16</code>，在 LeNet 模型的论文中将这一层称为卷积层，但是因为 filter 的大小就是 <code>5×5</code>，所以和全连接层没有区别。如果将 <code>5×5×16</code> 矩阵中的节点拉成一个向量，那么这一层和全连接层输入就一样了。本层的输出节点个数为 <code>120</code>个，总共有 <code>5×5×16×120+120=48120</code> 个参数。</p>
<h2 id="第六层：全连接层"><a href="#第六层：全连接层" class="headerlink" title="第六层：全连接层"></a>第六层：全连接层</h2><p>本层的输入节点个数为 <code>120</code> 个，输出节点个数为 <code>84</code> 个，总共参数为 <code>120×84+84=10164</code>个。</p>
<h2 id="第七层：全连接层"><a href="#第七层：全连接层" class="headerlink" title="第七层：全连接层"></a>第七层：全连接层</h2><p>本层的输入节点个数为 <code>84</code> 个，输出节点个数为 <code>10</code> 个，总共参数为 <code>84×10+10=850</code> 个 。</p>
<h1 id="RCNN"><a href="#RCNN" class="headerlink" title="RCNN"></a>RCNN</h1><h2 id="整体过程："><a href="#整体过程：" class="headerlink" title="整体过程："></a>整体过程：</h2><ol>
<li>输入一张多目标图像，采用<em>selective search</em>算法提取约<code>2000</code>个建议框</li>
<li>先在每个建议框周围加上<code>16</code>个像素值为建议框像素平均值的边框，再直接变形为<code>227×227</code>的大小</li>
<li>先将所有建议框像素减去该建议框像素平均值后【预处理操作】，再依次将每个<code>227×227</code>的建议框输入<em>AlexNet CNN</em>网络获取<code>4096</code>维的特征【比以前的人工经验特征低两个数量级】，<code>2000</code>个建议框的CNN特征组合成<code>2000×4096</code>维矩阵</li>
<li>将<code>2000×4096</code>维特征与<code>20</code>个SVM组成的权值矩阵<code>4096×20</code>相乘【<code>20</code>种分类，SVM是二分类器，则有<code>20</code>个SVM】，获得<code>2000×20</code>维矩阵表示每个建议框是某个物体类别的得分</li>
<li>分别对上述<code>2000×20</code>维矩阵中每一列即每一类进行非极大值抑制剔除重叠建议框，得到该列即该类中得分最高的一些建议框</li>
<li>分别用<code>20</code>个回归器对上述<code>20</code>个类别中剩余的建议框进行回归操作，最终得到每个类别的修正后的得分最高的bounding box</li>
</ol>
<h2 id="1-算法的整体思路"><a href="#1-算法的整体思路" class="headerlink" title="1. 算法的整体思路"></a>1. 算法的整体思路</h2><p>通过利用<em>recongnition using regions</em>操作来解决CNN的定位问题，此方法在目标检测和语义分割中都取得了成功。测试阶段，此方法对每一个输入的图片产生近<code>2000</code>个不分种类的<em>region proposals</em>，使用CNN从每个<em>region proposals</em>中提取一个固定长度的特征向量，然后对每个<em>region proposal</em>提取的特征向量使用特定种类的线性SVM进行分类（CNN+SVM for classification）。</p>
<p>RCNN采用的方法是：首先输入一张图片，先定位出<code>2000</code>个物体候选框，然后采用CNN提取每个候选框中图片的特征向量，特征向量的维度为<code>4096</code>维，接着采用SVM算法对各个候选框中的物体进行分类识别。</p>
<p>RCNN算法主要分为四个步骤：</p>
<ol>
<li>找出候选框（一张图像生成<code>1K~2K</code>个候选区域 ）</li>
<li>利用CNN提取特征向量（对每个候选区域，使用深度网络提取特征 ）</li>
<li>利用SVM进行特征向量分类（ 特征送入每一类的SVM 分类器，判别是否属于该类）</li>
<li>使用回归器精细修正候选框位置</li>
</ol>
<p><img src="https://upload-images.jianshu.io/upload_images/1351548-8980bce3730d6a7e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p>
<h2 id="2-候选框的搜索"><a href="#2-候选框的搜索" class="headerlink" title="2. 候选框的搜索"></a>2. 候选框的搜索</h2><p>当输入一张图片时，搜索出所有可能是物体的区域，这个采用的方法是传统文献的算法：《Selective Search for Object Recognition》，通过这个算法可以搜索出<code>2000</code>个候选框（搜出的候选框是矩形的，而且是大小各不相同）。然而，CNN对输入图片的大小的要求是固定的，如果把搜索到的矩形选框不做处理，就扔进CNN中，肯定不行。</p>
<p>因此，对于每个输入的候选框都需要缩放到固定的大小。为了简单起见，假设下一阶段CNN所需要的输入图片大小是个正方形图片：<code>227×227</code>。由于经过<em>selective search</em>得到的是矩形框，可以采用两种不同的处理方法：</p>
<h3 id="各向异性缩放"><a href="#各向异性缩放" class="headerlink" title="各向异性缩放"></a>各向异性缩放</h3><p>即不管图片的长宽比例，也不管其是否扭曲，直接缩放成CNN输入的大小<code>227×227</code>（如图<code>(D)</code>所示）。</p>
<h3 id="各向同性缩放"><a href="#各向同性缩放" class="headerlink" title="各向同性缩放"></a>各向同性缩放</h3><p>因为图片扭曲后，可能会对后续CNN的训练精度有影响。各向同性缩放有两种方案：</p>
<ol>
<li>直接在原始图片中，把bounding box的边界扩展延伸成正方形，然后再进行裁剪；如果已经延伸到了原始图片的外边界，那么就用bounding box中的颜色均值填充（如图<code>(B)</code>所示）。</li>
<li>先把bounding box图片裁剪出来，然后用固定的背景颜色填充成正方形图片（背景颜色也采用bounding box的像素颜色均值，如图<code>(C)</code>所示）。</li>
</ol>
<p><img src="https://upload-images.jianshu.io/upload_images/1351548-2a5b0f40b0e82d33.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p>
<p>得到指定大小的图片后，后面还要继续用这<code>2000</code>个候选框图片继续训练CNN、SVM。在一张图中，人工标注时就只标注了正确的bounding box，搜索出来的<code>2000</code>个矩形框不可能会出现一个与人工标注完全匹配的候选框。</p>
<p>因此，需要用<code>IoU</code>为<code>2000</code>个bounding box打标签，以便下一步CNN训练使用。在CNN阶段，如果用<em>selective search</em>挑选出来的候选框与物体的人工标注矩形框的重叠<code>IoU</code>大于<code>0.5</code>，就把这个候选框标注成物体类别，否则就把它当做背景类别。</p>
<h3 id="非极大值抑制的具体操作"><a href="#非极大值抑制的具体操作" class="headerlink" title="非极大值抑制的具体操作"></a>非极大值抑制的具体操作</h3><p>在测试过程完成到第<code>4</code>步之后，获得<code>2000×20</code>维矩阵表示每个建议框是某个物体类别的得分情况，此时会遇到下图所示情况，同一个车辆目标会被多个建议框包围，这时需要非极大值抑制操作去除得分较低的候选框以减少重叠框。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/1351548-994e742fcbc5f915.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p>
<h4 id="步骤："><a href="#步骤：" class="headerlink" title="步骤："></a>步骤：</h4><ol>
<li>对<code>2000×20</code>维矩阵中每列按从大到小进行排序</li>
<li>从每列最大的得分建议框开始，分别与该列后面的得分建议框进行<code>IoU</code>计算，若<code>IoU &gt; 阈值</code>，则剔除得分较小的建议框，否则认为图像中存在多个同一类物体</li>
<li>从每列次大的得分建议框开始，重复步骤<code>2</code> </li>
<li>重复步骤<code>3</code>，直到遍历完该列所有建议框</li>
<li>遍历完<code>2000×20</code>维矩阵所有列，即所有物体种类都做一遍非极大值抑制</li>
<li>最后剔除各个类别中剩余建议框得分少于该类别阈值的建议框</li>
</ol>
<h2 id="3-CNN特征提取"><a href="#3-CNN特征提取" class="headerlink" title="3. CNN特征提取"></a>3. CNN特征提取</h2><h3 id="1-网络结构设计"><a href="#1-网络结构设计" class="headerlink" title="1. 网络结构设计"></a>1. 网络结构设计</h3><p>网络结构有两个可选方案：</p>
<ul>
<li>经典的<em>Alexnet</em></li>
<li><em>VGG16</em></li>
</ul>
<p>经过测试，<em>Alexnet</em>精度为<code>58.5%</code>，<em>VGG16</em>精度为<code>66%</code>。<em>VGG</em>模型的特点是：<strong>选择比较小的卷积核、选择较小的跨步，这个网络的精度高，不过计算量是<em>Alexnet</em>的<code>7</code>倍</strong>。</p>
<p>为简单起见，直接选用<em>Alexnet</em>。<em>Alexnet</em>特征提取部分包含了<code>5</code>个卷积层、<code>2</code>个全连接层，在<em>Alexnet</em>中<code>p5</code>层神经元个数为<code>9216</code>，<code>f6</code>、<code>f7</code>的神经元个数都是<code>4096</code>，通过这个网络训练完毕后，最后提取特征每个输入候选框图片都能得到一个<code>4096</code>维的特征向量。</p>
<h3 id="2-有监督预训练"><a href="#2-有监督预训练" class="headerlink" title="2. 有监督预训练"></a>2. 有监督预训练</h3><p>参数初始化部分：物体检测的一个难点在于，物体标签训练数据少，如果直接采用随机初始化CNN参数的方法，那么目前的训练数据量是远远不够的。</p>
<p>这种情况下，最好的是采用某些方法，把参数初始化了，然后再进行有监督的参数微调。RCNN采用有监督的预训练，所以在设计网络结构时，直接用<em>Alexnet</em>的网络（连参数也是直接采用它的参数，作为初始的参数值，然后再fine-tuning训练）。</p>
<p>网络优化求解：采用随机梯度下降法，学习速率大小为<code>0.001</code>。</p>
<h3 id="3-fine-tuning训练"><a href="#3-fine-tuning训练" class="headerlink" title="3. fine-tuning训练"></a>3. <em>fine-tuning</em>训练</h3><p>采用<em>selective search</em>搜索出来的候选框，处理到指定的大小，继续对上面预训练的CNN模型进行<em>fine-tuning</em>训练。</p>
<p>假设要检测的物体类别有<code>N</code>类，那么就需要把上面预训练阶段的CNN模型的最后一层给替换掉，替换成<code>N+1</code>个输出的神经元(加<code>1</code>，表示还有一个背景)，然后这一层直接采用参数随机初始化的方法，其它网络层的参数不变</p>
<p>接着进行<em>SGD</em>训练。开始的时候，<em>SGD</em>学习率选择<code>0.001</code>，在每次训练的时候，batch size大小选择<code>128</code>（其中，<code>32</code>个为正样本、<code>96</code>个为负样本）。</p>
<h3 id="疑问"><a href="#疑问" class="headerlink" title="疑问"></a>疑问</h3><h4 id="1-既然CNN都是用于提取特征，那么直接用Alexnet做特征提取，省去fine-tuning阶段可以吗？"><a href="#1-既然CNN都是用于提取特征，那么直接用Alexnet做特征提取，省去fine-tuning阶段可以吗？" class="headerlink" title="1. 既然CNN都是用于提取特征，那么直接用Alexnet做特征提取，省去fine-tuning阶段可以吗？"></a>1. 既然CNN都是用于提取特征，那么直接用<em>Alexnet</em>做特征提取，省去<em>fine-tuning</em>阶段可以吗？</h4><p>可以。可以不需重新训练CNN，直接采用<em>Alexnet</em>模型，提取出<code>p5</code>或者<code>f6</code>、<code>f7</code>的特征作为特征向量，然后进行训练SVM（只不过这样精度会比较低）。</p>
<h4 id="2-没有fine-tuning的时候，要选择哪一层的特征作为CNN提取到的特征呢？由于可以选择p5、f6、f7，这三层的神经元个数分别是9216、4096、4096。从p5到p6这层的参数个数是：4096-9216，从f6到f7的参数是4096-4096。那么具体是选择p5、f6还是f7呢？"><a href="#2-没有fine-tuning的时候，要选择哪一层的特征作为CNN提取到的特征呢？由于可以选择p5、f6、f7，这三层的神经元个数分别是9216、4096、4096。从p5到p6这层的参数个数是：4096-9216，从f6到f7的参数是4096-4096。那么具体是选择p5、f6还是f7呢？" class="headerlink" title="2. 没有fine-tuning的时候，要选择哪一层的特征作为CNN提取到的特征呢？由于可以选择p5、f6、f7，这三层的神经元个数分别是9216、4096、4096。从p5到p6这层的参数个数是：4096*9216，从f6到f7的参数是4096*4096。那么具体是选择p5、f6还是f7呢？"></a>2. 没有<em>fine-tuning</em>的时候，要选择哪一层的特征作为CNN提取到的特征呢？由于可以选择<code>p5</code>、<code>f6</code>、<code>f7</code>，这三层的神经元个数分别是<code>9216</code>、<code>4096</code>、<code>4096</code>。从<code>p5</code>到<code>p6</code>这层的参数个数是：<code>4096*9216</code>，从<code>f6</code>到<code>f7</code>的参数是<code>4096*4096</code>。那么具体是选择<code>p5</code>、<code>f6</code>还是<code>f7</code>呢？</h4><p>RCNN论文证明了一个理论：如果不进行<em>fine-tuning</em>，即直接把<em>Alexnet</em>模型当做万金油使用，类似于<em>HOG</em>、<em>SIFT</em>一样做特征提取，不针对特定的任务，然后把提取的特征用于分类，结果发现<code>p5</code>的精度竟然跟<code>f6</code>、<code>f7</code>差不多，而且<code>f6</code>提取到的特征还比<code>f7</code>的精度略高；如果进行了<em>fine-tuning</em>，那么<code>f7</code>、<code>f6</code>提取到的特征就会让训练的SVM分类器的精度飙涨。</p>
<p>据此，如果不针对特定任务进行<em>fine-tuning</em>，而是把CNN当做特征提取器的话，卷积层所学到的特征其实就是基础的共享特征提取层，就类似于SIFT算法一样，可以用于提取各种图片的特征，而<code>f6</code>、<code>f7</code>所学习到的特征是用于针对特定任务的特征。打个比方：对于人脸性别识别来说，一个CNN模型前面的卷积层所学习到的特征就类似于学习人脸共性特征，然后全连接层所学习的特征就是针对性别分类的特征。</p>
<h4 id="3-CNN在进行训练的时候，本来就是对bounding-box的物体进行识别分类训练，是一个端到端的任务。在训练的最后一层softmax就是分类层，那么为什么要先用CNN做特征提取（提取fc7层数据），然后再把提取的特征用于训练SVM分类器？"><a href="#3-CNN在进行训练的时候，本来就是对bounding-box的物体进行识别分类训练，是一个端到端的任务。在训练的最后一层softmax就是分类层，那么为什么要先用CNN做特征提取（提取fc7层数据），然后再把提取的特征用于训练SVM分类器？" class="headerlink" title="3. CNN在进行训练的时候，本来就是对bounding box的物体进行识别分类训练，是一个端到端的任务。在训练的最后一层softmax就是分类层，那么为什么要先用CNN做特征提取（提取fc7层数据），然后再把提取的特征用于训练SVM分类器？"></a>3. CNN在进行训练的时候，本来就是对bounding box的物体进行识别分类训练，是一个端到端的任务。在训练的最后一层<em>softmax</em>就是分类层，那么为什么要先用CNN做特征提取（提取<code>fc7</code>层数据），然后再把提取的特征用于训练SVM分类器？</h4><p>这是因为SVM训练和CNN训练过程的正负样本定义方式各有不同，导致最后采用CNN softmax输出比采用SVM精度还低。</p>
<p>CNN在训练的时候，对训练数据做了比较宽松的标注（比如一个bounding box可能只包含物体的一部分），那么把它也标注为正样本，用于训练CNN；采用这个方法的主要原因在于CNN容易过拟合，所以需要大量的训练数据。在CNN训练阶段，是对bounding box的位置限制条件限制的比较松(<code>IoU</code>只要大于<code>0.5</code>都被标注为正样本)；</p>
<p>然而SVM训练的时候，因为SVM适用于少样本训练，所以对于训练样本数据的<code>IoU</code>要求比较严格，只有当bounding box把整个物体都包含进去了，才把它标注为物体类别，然后训练SVM。</p>
<h4 id="4-为什么需要回归器？"><a href="#4-为什么需要回归器？" class="headerlink" title="4. 为什么需要回归器？"></a>4. 为什么需要回归器？</h4><p>目标检测不仅是要对目标进行识别，还要完成定位任务，所以最终获得的bounding-box也决定了目标检测的精度（定位精度可以用算法得出的物体检测框与实际标注的物体边界框的<code>IoU</code>值来近似表示）。</p>
<p>如下图所示，绿色框为实际标准的卡宴车辆框，即Ground Truth；黄色框为<em>selective search</em>算法得出的建议框，即Region Proposal。即使黄色框中物体被分类器识别为卡宴车辆，但是由于绿色框和黄色框<code>IoU</code>值并不大，所以最后的目标检测精度并不高。采用回归器是为了对建议框进行校正，使得校正后的Region Proposal与<em>selective search</em>更接近， 以提高最终的检测精度。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/1351548-a8e13a1891d2f2b2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p>
<h4 id="如何设计回归器（Bounding-box-regression）？"><a href="#如何设计回归器（Bounding-box-regression）？" class="headerlink" title="如何设计回归器（Bounding-box regression）？"></a>如何设计回归器（Bounding-box regression）？</h4><p>如下图所示，黄色框口<code>P</code>表示建议框Region Proposal，绿色窗口<code>G</code>表示实际框Ground Truth，红色窗口表示Region Proposal进行回归后的预测窗口。现在的目标是：找到<code>P</code>的线性变换【当Region Proposal与Ground Truth的<code>IoU &gt; 0.6</code>时，可以认为是线性变换】，使得与<code>G</code>越相近，这就相当于一个可以用最小二乘法解决的线性回归问题。</p>
<p><img src="https://upload-images.jianshu.io/upload_images/1351548-caf7d246cb76372b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p>
<p><code>P</code>窗口的数学表达式：<img src="https://upload-images.jianshu.io/upload_images/1351548-c8c359a767422ca3.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="">，其中表示第<code>i</code>个窗口的中心点坐标，<br><img src="https://upload-images.jianshu.io/upload_images/1351548-702ecd0e93aa424d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="">分别为第<code>i</code>个窗口的宽和高</p>
<p><code>G</code>窗口的数学表达式为：<img src="https://upload-images.jianshu.io/upload_images/1351548-e8debf684ccb4c6a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="">。 </p>
<p>定义四种变换函数<img src="https://upload-images.jianshu.io/upload_images/1351548-3d2f421e8b246347.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="">和<img src="https://upload-images.jianshu.io/upload_images/1351548-80e0e68c9f14c187.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="">（即，通过平移对<code>x</code>和<code>y</code>进行变化，通过缩放对<code>w</code>和<code>h</code>进行变化）：</p>
<p><img src="https://upload-images.jianshu.io/upload_images/1351548-7d66da72dae05358.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p>
<p>每一个函数<img src="https://upload-images.jianshu.io/upload_images/1351548-f76229a3f16e64d0.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="">【<img src="https://upload-images.jianshu.io/upload_images/1351548-0264e01165b94213.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="">表示<img src="https://upload-images.jianshu.io/upload_images/1351548-6bdc48bd16750c5f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="">中的一个】都是一个<em>AlexNet</em> CNN网络的<img src="https://upload-images.jianshu.io/upload_images/1351548-1f68ce4afa19558b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="">层特征（用<img src="https://upload-images.jianshu.io/upload_images/1351548-59295275a54393c0.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="">表示）的线性函数。所以有<img src="https://upload-images.jianshu.io/upload_images/1351548-916467909df38793.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="">，其中，<img src="https://upload-images.jianshu.io/upload_images/1351548-dedf7ed6344d06bb.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="">为可学习模型参数（learnable<br>model parameters）的向量，它就是所需要学习的回归参数。</p>
<p>损失函数（使用岭回归）为：</p>
<p><img src="https://upload-images.jianshu.io/upload_images/1351548-d9dc5ab538a7d48b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p>
<p>损失函数中加入正则项是为了避免归回参数过大。其中，回归目标（<img src="https://upload-images.jianshu.io/upload_images/1351548-d8cc2bba0073551c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="">）由训练输入对按下式计算得来：</p>
<p><img src="https://upload-images.jianshu.io/upload_images/1351548-196e59564c32e911.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p>
<p><strong>回归的整体过程为：</strong></p>
<ol>
<li>构造样本对。为了提高每类样本框回归的有效性，对每类样本都仅仅采集与Ground Truth相交<code>IoU</code>最大的Region Proposal，并且<code>IoU &gt; 0.6</code>的Region Proposal作为样本对，一共产生<code>20</code>对样本对【<code>20</code>个类别】 </li>
<li>每种类型的回归器进行单独训练，输入该类型样本对<code>N</code>个以及其所对应的<em>AlexNet</em> CNN网络<img src="https://upload-images.jianshu.io/upload_images/1351548-421cfeb01de6f46e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="">层特征 </li>
<li>利用<code>(6)-(9)</code>式和输入样本对进行计算 </li>
<li>根据损失函数<code>(5)</code>进行回归，得到使损失函数最小的参数</li>
</ol>
<h2 id="4-SVM训练"><a href="#4-SVM训练" class="headerlink" title="4. SVM训练"></a>4. SVM训练</h2><p>这是一个二分类问题，我么假设要检测车辆。只有当bounding box把整量车都包含在内，那才叫正样本；如果bounding box 没有包含到车辆，那么就可以把它当做负样本。</p>
<p>但问题是当检测窗口只有部分包含物体，那该怎么定义正负样本呢？通过训练发现，如果选择<code>IoU</code>阈值为<code>0.3</code>效果最好，即当重叠度小于<code>0.3</code>的时候，就把它标注为负样本。一旦CNN <code>f7</code>层特征被提取出来，那么将为每个物体累训练一个SVM分类器。当用CNN提取<code>2000</code>个候选框，可以得到<code>2000×4096</code>的特征向量矩阵，然后只需要把这样的一个矩阵与SVM权值矩阵<code>4096×N</code>点乘(<code>N</code>为分类类别数目，因为训练的<code>N</code>个SVM，每个SVM包含了<code>4096</code>个<code>W</code>)，就可以得到结果。</p>
<p>图片分类标注好的训练数据非常多，但是物体检测的标注数据却很少，如何用少量的标注数据，训练高质量的模型，这就是RCNN最大的特点。其采用了迁移学习的思想：先利用<em>ILSVRC2012</em>这个训练数据库（一个图片分类训练数据库，其拥有大量的标注数据，共包含了<code>1000</code>种类别物体），进行网络的图片分类训练。因此，预训练阶段CNN模型的输出是<code>1000</code>个神经元，或者也可以直接采用<em>Alexnet</em>训练好的模型参数。</p>
<p><strong>扩展阅读：</strong></p>
<ul>
<li><a href="https://blog.csdn.net/u014696921/article/details/52824097" target="_blank" rel="noopener">R-CNN论文详解</a></li>
<li><a href="https://arxiv.org/pdf/1311.2524.pdf" target="_blank" rel="noopener">RCNN论文</a></li>
</ul>
<h1 id="AlexNet"><a href="#AlexNet" class="headerlink" title="AlexNet"></a>AlexNet</h1><h2 id="1-模型结构"><a href="#1-模型结构" class="headerlink" title="1. 模型结构"></a>1. 模型结构</h2><p><img src="https://upload-images.jianshu.io/upload_images/1351548-d33870250f3acd76.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p>
<p>如上图所示，采用是两台GPU服务器，所有会有两个流程图。该模型一共分为<code>8</code>层——<code>5</code>个卷积层，<code>3</code>个全连接层（个卷积层后面加了最大池化层)，包含<code>6</code>亿<code>3000</code>万个连接，<code>6000</code>万个参数和<code>65</code>万个神经元。。在每一个卷积层中，包含了激励函数<code>ReLU</code>以及局部响应归一化（<code>LRN</code>）处理，然后再经过降采样（<code>pool</code>处理）。</p>
<h2 id="2-创新点"><a href="#2-创新点" class="headerlink" title="2. 创新点"></a>2. 创新点</h2><ul>
<li>使用<code>ReLU</code>作为CNN的激活函数，验证了其效果在较深的网络中超过了<code>Sigmoid</code>，成功解决了<code>Sigmoid</code>在网络较深时的梯度弥散问题。</li>
<li>训练时使用<code>Dropout</code>随机忽略一部分神经元，以避免模型过拟合。一般在全连接层使用，在预测的时候是不使用<code>Dropout</code>的，即<code>Dropout</code>为<code>1</code>。</li>
<li>在CNN中使用重叠的最大池化(步长小于卷积核)。此前CNN中普遍使用平均池化，使用最大池化可以避免平均池化的模糊效果。同时重叠效果可以提升特征的丰富性。</li>
<li>提出<code>LRN</code>（Local Response Normalization，即局部响应归一化）层，对局部神经元的活动创建竞争机制，使得其中响应比较大的值变得相对更大，并抑制其他反馈较小的神经元，增强了模型的泛化能力。</li>
<li>使用CUDA加速神经网络的训练，利用了GPU强大的计算能力。</li>
<li>数据增强，随机的从<code>256*256</code>的图片中截取<code>224*224</code>大小的区域（以及水平翻转的镜像），相当于增加了<img src="https://upload-images.jianshu.io/upload_images/1351548-8abcfb2e5fb034f6.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="">倍的数据量，如果没有数据增强，模型会陷入过拟合中，使用数据增强可以增大模型的泛化能力。</li>
</ul>
<h1 id="Fast-RCNN"><a href="#Fast-RCNN" class="headerlink" title="Fast RCNN"></a>Fast RCNN</h1>
        
    

    
</div>


                

                <!-- Post Comments -->
                
                    
                
            </div>

            <!-- Post Prev & Next Nav -->
            <nav class="material-nav mdl-color-text--grey-50 mdl-cell mdl-cell--12-col">
    <!-- Prev Nav -->
    
        <a href="/2018/11/17/KCF/" id="post_nav-newer" class="prev-content">
            <button class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--icon mdl-color--white mdl-color-text--grey-900" role="presentation">
                <i class="material-icons">arrow_back</i>
            </button>
            &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
            新篇
        </a>
    

    <!-- Section Spacer -->
    <div class="section-spacer"></div>

    <!-- Next Nav -->
    
        <a href="/2018/11/05/ORB/" id="post_nav-older" class="next-content">
            旧篇
            &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
            <button class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--icon mdl-color--white mdl-color-text--grey-900" role="presentation">
                <i class="material-icons">arrow_forward</i>
            </button>
        </a>
    
</nav>

        </div>
    </div>



                    
                        <!-- Overlay For Active Sidebar -->
<div class="sidebar-overlay"></div>

<!-- Material sidebar -->
<aside id="sidebar" class="sidebar sidebar-colored sidebar-fixed-left" role="navigation">
    <div id="sidebar-main">
        <!-- Sidebar Header -->
        <div class="sidebar-header header-cover" style="background-image: url(/img/sidebar_header.png);">
    <!-- Top bar -->
    <div class="top-bar"></div>

    <!-- Sidebar toggle button -->
    <button type="button" class="sidebar-toggle mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--icon" style="display: initial;" data-upgraded=",MaterialButton,MaterialRipple">
        <i class="material-icons">clear_all</i>
        <span class="mdl-button__ripple-container">
            <span class="mdl-ripple">
            </span>
        </span>
    </button>

    <!-- Sidebar Avatar -->
    <div class="sidebar-image">
        <img src="/img/avatar.png" alt="Magicmanoooo's avatar">
    </div>

    <!-- Sidebar Email -->
    <a data-toggle="dropdown" class="sidebar-brand" href="#settings-dropdown">
        838713968@qq.com
        <b class="caret"></b>
    </a>
</div>


        <!-- Sidebar Navigation  -->
        <ul class="nav sidebar-nav">
    <!-- User dropdown  -->
    <li class="dropdown">
        <ul id="settings-dropdown" class="dropdown-menu">
            
                <li>
                    <a href="mailto: 838713968@qq.com" target="_blank" title="Email Me">
                        
                            <i class="material-icons sidebar-material-icons sidebar-indent-left1pc-element">email</i>
                        
                        Email Me
                    </a>
                </li>
            
        </ul>
    </li>

    <!-- Homepage -->
    
        <li id="sidebar-first-li">
            <a href="/">
                
                    <i class="material-icons sidebar-material-icons">home</i>
                
                主页
            </a>
        </li>
        
    

    <!-- Archives  -->
    
        <li class="dropdown">
            <a href="#" class="ripple-effect dropdown-toggle" data-toggle="dropdown">
                
                    <i class="material-icons sidebar-material-icons">inbox</i>
                
                    归档
                <b class="caret"></b>
            </a>
            <ul class="dropdown-menu">
            <li>
                <a class="sidebar_archives-link" href="/archives/2018/12/">十二月 2018<span class="sidebar_archives-count">1</span></a></li><li><a class="sidebar_archives-link" href="/archives/2018/11/">十一月 2018<span class="sidebar_archives-count">3</span></a></li><li><a class="sidebar_archives-link" href="/archives/2018/10/">十月 2018<span class="sidebar_archives-count">5</span></a></li><li><a class="sidebar_archives-link" href="/archives/2018/09/">九月 2018<span class="sidebar_archives-count">3</span></a></li><li><a class="sidebar_archives-link" href="/archives/2018/08/">八月 2018<span class="sidebar_archives-count">4</span></a></li><li><a class="sidebar_archives-link" href="/archives/2018/07/">七月 2018<span class="sidebar_archives-count">5</span></a>
            </ul>
        </li>
        
    

    <!-- Categories  -->
    
        <li class="dropdown">
            <a href="#" class="ripple-effect dropdown-toggle" data-toggle="dropdown">
                
                    <i class="material-icons sidebar-material-icons">chrome_reader_mode</i>
                
                分类
                <b class="caret"></b>
            </a>
            <ul class="dropdown-menu">
                <li>
                
            </ul>
        </li>
        
    

    <!-- Pages  -->
    

    <!-- Article Number  -->
    
        <li>
            <a href="/archives">
                文章总数
                <span class="sidebar-badge">21</span>
            </a>
        </li>
        
    
</ul>


        <!-- Sidebar Footer -->
        <!--
I'm glad you use this theme, the development is no so easy, I hope you can keep the copyright, I will thank you so much.
If you still want to delete the copyrights, could you still retain the first one? Which namely "Theme Material"
It will not impact the appearance and can give developers a lot of support :)

很高兴您使用并喜欢该主题，开发不易 十分谢谢与希望您可以保留一下版权声明。
如果您仍然想删除的话 能否只保留第一项呢？即 "Theme Material"
它不会影响美观并可以给开发者很大的支持和动力。 :)
-->

<!-- Sidebar Divider -->

    <div class="sidebar-divider"></div>


<!-- Theme Material -->


<!-- Help & Support -->
<!--

    <a href="mailto:hiviosey@gmail.com" class="sidebar-footer-text-a">
        <div class="sidebar-text mdl-button mdl-js-button mdl-js-ripple-effect sidebar-footer-text-div" data-upgraded=",MaterialButton,MaterialRipple">
        sidebar.help
        <span class="mdl-button__ripple-container">
          <span class="mdl-ripple"></span>
        </span>
      </div>
    </a>

-->

<!-- Feedback -->
<!--

    <a href="https://github.com/viosey/hexo-theme-material/issues" target="_blank" class="sidebar-footer-text-a">
        <div class="sidebar-text mdl-button mdl-js-button mdl-js-ripple-effect sidebar-footer-text-div" data-upgraded=",MaterialButton,MaterialRipple">
        sidebar.feedback
        <span class="mdl-button__ripple-container"><span class="mdl-ripple"></span></span></div>
    </a>

-->

<!-- About Theme -->
<!--

    <a href="https://blog.viosey.com/index.php/Material.html" target="_blank" class="sidebar-footer-text-a">
        <div class="sidebar-text mdl-button mdl-js-button mdl-js-ripple-effect sidebar-footer-text-div" data-upgraded=",MaterialButton,MaterialRipple">
             sidebar.about_theme
            <span class="mdl-button__ripple-container"><span class="mdl-ripple"></span></span></div>
    </a>

-->

    </div>

    <!-- Sidebar Image -->
    

</aside>

                    

                    
                        <!-- Footer Top Button -->
                        <div id="back-to-top" class="toTop-wrap">
    <a href="#top" class="toTop">
        <i class="material-icons footer_top-i">expand_less</i>
    </a>
</div>

                    

                    <!--Footer-->
<footer class="mdl-mini-footer" id="bottom">
    
        <!-- Paradox Footer Left Section -->
        <div class="mdl-mini-footer--left-section sns-list">
    <!-- Twitter -->
    

    <!-- Facebook -->
    

    <!-- Google + -->
    

    <!-- Weibo -->
    
        <a href="https://weibo.com/5345088988/profile?rightmod=1&amp;wvr=6&amp;mod=personinfo&amp;is_all=1" target="_blank">
            <button class="mdl-mini-footer--social-btn social-btn footer-sns-weibo">
                <span class="visuallyhidden">Weibo</span>
            </button><!--
     --></a>
    

    <!-- Instagram -->
    

    <!-- Tumblr -->
    

    <!-- Github -->
    
        <a href="https://github.com/Azurery" target="_blank">
            <button class="mdl-mini-footer--social-btn social-btn footer-sns-github">
                <span class="visuallyhidden">Github</span>
            </button><!--
     --></a>
    

    <!-- LinkedIn -->
    

    <!-- Zhihu -->
    
        <a href="https://www.zhihu.com/people/zhang-tao-60-41/activities" target="_blank">
            <button class="mdl-mini-footer--social-btn social-btn footer-sns-zhihu">
                <span class="visuallyhidden">Zhihu</span>
            </button><!--
     --></a>
    

    <!-- Bilibili -->
    
        <a href="https://space.bilibili.com/94222521/#/" target="_blank">
            <button class="mdl-mini-footer--social-btn social-btn footer-sns-bilibili">
                <span class="visuallyhidden">Bilibili</span>
            </button><!--
     --></a>
    

    <!-- Telegram -->
    
    
    <!-- V2EX -->
    
</div>


        <!--Copyright-->
        <div id="copyright">
            Copyright&nbsp;©&nbsp;2017&nbsp;-<script type="text/javascript">var fd = new Date();document.write("&nbsp;" + fd.getFullYear() + "&nbsp;");</script>Azurery
            
                <br>
                
                    只有永不遏止的奋斗，才能使青春之花，即使是凋谢，也是壮丽地凋谢
                
            
        </div>

        <!-- Paradox Footer Right Section -->

        <!--
        I am glad you use this theme, the development is no so easy, I hope you can keep the copyright.
        It will not impact the appearance and can give developers a lot of support :)

        很高兴您使用该主题，开发不易，希望您可以保留一下版权声明。
        它不会影响美观并可以给开发者很大的支持。 :)
        -->

        <div class="mdl-mini-footer--right-section">
            <div>
                <div class="footer-develop-div">Powered by <a href="https://hexo.io" target="_blank" class="footer-develop-a">Hexo</a></div>
                <div class="footer-develop-div">Theme - <a href="https://github.com/viosey/hexo-theme-material" target="_blank" class="footer-develop-a">Material</a></div>
            </div>
        </div>
    
</footer>


                    <!-- Import JS File -->

    <script>lsloader.load("lazyload_js","/js/lazyload.min.js?1BcfzuNXqV+ntF6gq+5X3Q==", true)</script>



    <script>lsloader.load("js_js","/js/js.min.js?V/53wGualMuiPM3xoetD5Q==", true)</script>



    <script>lsloader.load("np_js","/js/nprogress.js?pl3Qhb9lvqR1FlyLUna1Yw==", true)</script>


<script type="text/ls-javascript" id="NProgress-script">
    NProgress.configure({
        showSpinner: true
    });
    NProgress.start();
    $('#nprogress .bar').css({
        'background': '#29d'
    });
    $('#nprogress .peg').css({
        'box-shadow': '0 0 10px #29d, 0 0 15px #29d'
    });
    $('#nprogress .spinner-icon').css({
        'border-top-color': '#29d',
        'border-left-color': '#29d'
    });
    setTimeout(function() {
        NProgress.done();
        $('.fade').removeClass('out');
    }, 800);
</script>













<!-- UC Browser Compatible -->
<script>
	var agent = navigator.userAgent.toLowerCase();
	if(agent.indexOf('ucbrowser')>0) {
		document.write('<link rel="stylesheet" href="/css/uc.css">');
	   alert('由于 UC 浏览器使用极旧的内核，而本网站使用了一些新的特性。\n为了您能更好的浏览，推荐使用 Chrome 或 Firefox 浏览器。');
	}
</script>

<!-- Import prettify js  -->

    
        
            <script>lsloader.load("prettify_js","/js/prettify.min.js?WN07fivHQSMKWy7BmHBB6w==", true)</script>
        
    



<!-- Window Load -->
<!-- add class for prettify -->
<script type="text/ls-javascript" id="window-load">
    $(window).on('load', function() {
        // Post_Toc parent position fixed
        $('.post-toc-wrap').parent('.mdl-menu__container').css('position', 'fixed');
    });

    
        
            $(function() {
                $('pre').addClass('prettyprint linenums').attr('style', 'overflow:auto;');
                prettyPrint();
                })
        
    
    
</script>

<!-- MathJax Load-->


<!-- Bing Background -->


<script type="text/ls-javascript" id="lazy-load">
    // Offer LazyLoad
    queue.offer(function(){
        $('.lazy').lazyload({
            effect : 'show'
        });
    });

    // Start Queue
    $(document).ready(function(){
        setInterval(function(){
            queue.execNext();
        },200);
    });
</script>

<!-- Custom Footer -->



<script>
    (function(){
        var scriptList = document.querySelectorAll('script[type="text/ls-javascript"]')

        for (var i = 0; i < scriptList.length; ++i) {
            var item = scriptList[i];
            lsloader.runInlineScript(item.id,item.id);
        }
    })()
console.log('\n %c © Material Theme | Version: 1.5.0 | https://github.com/viosey/hexo-theme-material %c \n', 'color:#455a64;background:#e0e0e0;padding:5px 0;border-top-left-radius:5px;border-bottom-left-radius:5px;', 'color:#455a64;background:#e0e0e0;padding:5px 0;border-top-right-radius:5px;border-bottom-right-radius:5px;');
</script>

                </main>
            </div>
        </body>
    
</html>
